Traceback (most recent call last):
  File "/public/home/hang/software/anaconda3/envs/torch18/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/public/home/hang/software/anaconda3/envs/torch18/bin/fairseq-train", line 22, in importlib_load_entry_point
    for entry_point in distribution(dist_name).entry_points
  File "/public/home/hang/software/anaconda3/envs/torch18/lib/python3.8/importlib/metadata.py", line 445, in distribution
    return Distribution.from_name(distribution_name)
  File "/public/home/hang/software/anaconda3/envs/torch18/lib/python3.8/importlib/metadata.py", line 169, in from_name
    raise PackageNotFoundError(name)
importlib.metadata.PackageNotFoundError: fairseq
2022-09-29 17:54:31 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 10000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 10000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 200000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './nmt/models/zh_fr_train/checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='./nmt/data/zh_fr_train/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=10000, max_tokens_valid=10000, max_update=200000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=8, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./nmt/models/zh_fr_train/checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang='zh', stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang='fr', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': './nmt/data/zh_fr_train/data-bin', 'source_lang': 'zh', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.001]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-09-29 17:54:31 | INFO | fairseq.tasks.translation | [zh] dictionary: 35400 types
2022-09-29 17:54:31 | INFO | fairseq.tasks.translation | [fr] dictionary: 31312 types
2022-09-29 17:54:32 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(35400, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(31312, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=31312, bias=False)
  )
)
2022-09-29 17:54:32 | INFO | fairseq_cli.train | task: TranslationTask
2022-09-29 17:54:32 | INFO | fairseq_cli.train | model: TransformerModel
2022-09-29 17:54:32 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-09-29 17:54:32 | INFO | fairseq_cli.train | num. shared model params: 113,228,800 (num. trained: 113,228,800)
2022-09-29 17:54:32 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-09-29 17:54:32 | INFO | fairseq.data.data_utils | loaded 2,456 examples from: ./nmt/data/zh_fr_train/data-bin/valid.zh-fr.zh
2022-09-29 17:54:32 | INFO | fairseq.data.data_utils | loaded 2,456 examples from: ./nmt/data/zh_fr_train/data-bin/valid.zh-fr.fr
2022-09-29 17:54:32 | INFO | fairseq.tasks.translation | ./nmt/data/zh_fr_train/data-bin valid zh-fr 2456 examples
2022-09-29 17:54:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-09-29 17:54:35 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-PCIE-32GB                    
2022-09-29 17:54:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-09-29 17:54:35 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-09-29 17:54:35 | INFO | fairseq_cli.train | max tokens per device = 10000 and max sentences per device = None
2022-09-29 17:54:35 | INFO | fairseq.trainer | Preparing to load checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint_last.pt
2022-09-29 17:54:36 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-09-29 17:54:42 | INFO | fairseq.trainer | Loaded checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint_last.pt (epoch 7 @ 1884 updates)
2022-09-29 17:54:42 | INFO | fairseq.trainer | loading train data for epoch 7
2022-09-29 17:54:42 | INFO | fairseq.data.data_utils | loaded 94,886 examples from: ./nmt/data/zh_fr_train/data-bin/train.zh-fr.zh
2022-09-29 17:54:42 | INFO | fairseq.data.data_utils | loaded 94,886 examples from: ./nmt/data/zh_fr_train/data-bin/train.zh-fr.fr
2022-09-29 17:54:42 | INFO | fairseq.tasks.translation | ./nmt/data/zh_fr_train/data-bin train zh-fr 94886 examples
2022-09-29 17:54:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 17:54:42 | INFO | fairseq.trainer | begin training epoch 7
2022-09-29 17:54:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 17:54:48 | INFO | train_inner | epoch 007:     16 / 314 loss=7.662, nll_loss=6.51, ppl=91.13, wps=20769.2, ups=2.65, wpb=7836, bsz=303.5, num_updates=1900, lr=0.000475052, gnorm=1.145, train_wall=6, gb_free=24.3, wall=13
2022-09-29 17:55:24 | INFO | train_inner | epoch 007:    116 / 314 loss=7.602, nll_loss=6.437, ppl=86.64, wps=20240.6, ups=2.79, wpb=7266.3, bsz=258.2, num_updates=2000, lr=0.00050005, gnorm=1.104, train_wall=36, gb_free=24.2, wall=49
2022-09-29 17:56:01 | INFO | train_inner | epoch 007:    216 / 314 loss=7.623, nll_loss=6.456, ppl=87.77, wps=21069.9, ups=2.72, wpb=7741.9, bsz=291.1, num_updates=2100, lr=0.000525047, gnorm=1.151, train_wall=37, gb_free=24, wall=86
2022-09-29 17:56:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
/public/home/hang/software/anaconda3/envs/torch18/lib/python3.8/site-packages/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-09-29 17:56:39 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 7.392 | nll_loss 6.135 | ppl 70.29 | wps 48554.8 | wpb 4813.2 | bsz 188.9 | num_updates 2198 | best_loss 7.392
2022-09-29 17:56:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 2198 updates
2022-09-29 17:56:39 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint7.pt
2022-09-29 17:56:42 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint7.pt
2022-09-29 17:56:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint7.pt (epoch 7 @ 2198 updates, score 7.392) (writing took 6.57991581200622 seconds)
2022-09-29 17:56:46 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-09-29 17:56:46 | INFO | train | epoch 007 | loss 7.595 | nll_loss 6.425 | ppl 85.93 | wps 19579.1 | ups 2.54 | wpb 7710.3 | bsz 302.2 | num_updates 2198 | lr 0.000549545 | gnorm 1.108 | train_wall 115 | gb_free 23.8 | wall 131
2022-09-29 17:56:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 17:56:46 | INFO | fairseq.trainer | begin training epoch 8
2022-09-29 17:56:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 17:56:47 | INFO | train_inner | epoch 008:      2 / 314 loss=7.544, nll_loss=6.366, ppl=82.46, wps=17695.3, ups=2.18, wpb=8133.2, bsz=358.9, num_updates=2200, lr=0.000550045, gnorm=1.06, train_wall=37, gb_free=23.7, wall=132
2022-09-29 17:57:24 | INFO | train_inner | epoch 008:    102 / 314 loss=7.356, nll_loss=6.147, ppl=70.86, wps=20531, ups=2.71, wpb=7569.8, bsz=322, num_updates=2300, lr=0.000575042, gnorm=1.314, train_wall=37, gb_free=23.8, wall=169
2022-09-29 17:58:00 | INFO | train_inner | epoch 008:    202 / 314 loss=7.332, nll_loss=6.114, ppl=69.27, wps=21014.8, ups=2.74, wpb=7660.7, bsz=302.2, num_updates=2400, lr=0.00060004, gnorm=1.117, train_wall=36, gb_free=24, wall=205
2022-09-29 17:58:37 | INFO | train_inner | epoch 008:    302 / 314 loss=7.252, nll_loss=6.019, ppl=64.85, wps=20958.8, ups=2.71, wpb=7735.1, bsz=275.7, num_updates=2500, lr=0.000625037, gnorm=1.047, train_wall=37, gb_free=23.9, wall=242
2022-09-29 17:58:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 17:58:43 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 7.215 | nll_loss 5.916 | ppl 60.37 | wps 48512.6 | wpb 4813.2 | bsz 188.9 | num_updates 2512 | best_loss 7.215
2022-09-29 17:58:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 2512 updates
2022-09-29 17:58:43 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint8.pt
2022-09-29 17:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint8.pt
2022-09-29 17:58:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint8.pt (epoch 8 @ 2512 updates, score 7.215) (writing took 6.218321138061583 seconds)
2022-09-29 17:58:49 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-09-29 17:58:49 | INFO | train | epoch 008 | loss 7.308 | nll_loss 6.087 | ppl 68 | wps 19614.3 | ups 2.54 | wpb 7710.3 | bsz 302.2 | num_updates 2512 | lr 0.000628037 | gnorm 1.147 | train_wall 115 | gb_free 23.8 | wall 254
2022-09-29 17:58:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 17:58:49 | INFO | fairseq.trainer | begin training epoch 9
2022-09-29 17:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 17:59:22 | INFO | train_inner | epoch 009:     88 / 314 loss=7.112, nll_loss=5.859, ppl=58.05, wps=17054.9, ups=2.24, wpb=7613.4, bsz=292, num_updates=2600, lr=0.000650035, gnorm=1.233, train_wall=37, gb_free=23.5, wall=287
2022-09-29 17:59:58 | INFO | train_inner | epoch 009:    188 / 314 loss=7.07, nll_loss=5.803, ppl=55.85, wps=21873.2, ups=2.74, wpb=7972.4, bsz=304.2, num_updates=2700, lr=0.000675032, gnorm=1.133, train_wall=36, gb_free=23.6, wall=323
2022-09-29 18:00:35 | INFO | train_inner | epoch 009:    288 / 314 loss=7.064, nll_loss=5.796, ppl=55.56, wps=20856, ups=2.74, wpb=7609.6, bsz=304.4, num_updates=2800, lr=0.00070003, gnorm=1.158, train_wall=36, gb_free=23.4, wall=360
2022-09-29 18:00:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:00:46 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 7.12 | nll_loss 5.774 | ppl 54.72 | wps 48406.5 | wpb 4813.2 | bsz 188.9 | num_updates 2826 | best_loss 7.12
2022-09-29 18:00:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 2826 updates
2022-09-29 18:00:46 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint9.pt
2022-09-29 18:00:48 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint9.pt
2022-09-29 18:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint9.pt (epoch 9 @ 2826 updates, score 7.12) (writing took 6.775245324941352 seconds)
2022-09-29 18:00:53 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-09-29 18:00:53 | INFO | train | epoch 009 | loss 7.076 | nll_loss 5.812 | ppl 56.19 | wps 19642.4 | ups 2.55 | wpb 7710.3 | bsz 302.2 | num_updates 2826 | lr 0.000706529 | gnorm 1.176 | train_wall 114 | gb_free 23.7 | wall 377
2022-09-29 18:00:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:00:53 | INFO | fairseq.trainer | begin training epoch 10
2022-09-29 18:00:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:01:20 | INFO | train_inner | epoch 010:     74 / 314 loss=6.824, nll_loss=5.522, ppl=45.95, wps=17479.6, ups=2.22, wpb=7863.8, bsz=302.6, num_updates=2900, lr=0.000725027, gnorm=1.064, train_wall=37, gb_free=23.5, wall=405
2022-09-29 18:01:57 | INFO | train_inner | epoch 010:    174 / 314 loss=6.867, nll_loss=5.564, ppl=47.3, wps=20517.2, ups=2.71, wpb=7580.6, bsz=306.5, num_updates=3000, lr=0.000750025, gnorm=1.193, train_wall=37, gb_free=24.5, wall=442
2022-09-29 18:02:34 | INFO | train_inner | epoch 010:    274 / 314 loss=6.849, nll_loss=5.54, ppl=46.53, wps=21172.5, ups=2.69, wpb=7861.4, bsz=320.1, num_updates=3100, lr=0.000775022, gnorm=1.093, train_wall=37, gb_free=23.8, wall=479
2022-09-29 18:02:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:02:50 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 7.105 | nll_loss 5.74 | ppl 53.43 | wps 48282.5 | wpb 4813.2 | bsz 188.9 | num_updates 3140 | best_loss 7.105
2022-09-29 18:02:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 3140 updates
2022-09-29 18:02:50 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint10.pt
2022-09-29 18:02:52 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint10.pt
2022-09-29 18:02:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint10.pt (epoch 10 @ 3140 updates, score 7.105) (writing took 6.212043527048081 seconds)
2022-09-29 18:02:56 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-09-29 18:02:56 | INFO | train | epoch 010 | loss 6.833 | nll_loss 5.525 | ppl 46.06 | wps 19617.8 | ups 2.54 | wpb 7710.3 | bsz 302.2 | num_updates 3140 | lr 0.000785021 | gnorm 1.119 | train_wall 115 | gb_free 23.8 | wall 501
2022-09-29 18:02:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:02:56 | INFO | fairseq.trainer | begin training epoch 11
2022-09-29 18:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:03:18 | INFO | train_inner | epoch 011:     60 / 314 loss=6.677, nll_loss=5.344, ppl=40.61, wps=17044.6, ups=2.25, wpb=7572.6, bsz=293, num_updates=3200, lr=0.00080002, gnorm=1.09, train_wall=36, gb_free=23.9, wall=523
2022-09-29 18:03:55 | INFO | train_inner | epoch 011:    160 / 314 loss=6.578, nll_loss=5.223, ppl=37.36, wps=21516.4, ups=2.7, wpb=7957.5, bsz=317.8, num_updates=3300, lr=0.000825017, gnorm=1.089, train_wall=37, gb_free=23.6, wall=560
2022-09-29 18:04:31 | INFO | train_inner | epoch 011:    260 / 314 loss=6.717, nll_loss=5.38, ppl=41.65, wps=20451.1, ups=2.79, wpb=7330, bsz=293, num_updates=3400, lr=0.000850015, gnorm=1.151, train_wall=36, gb_free=23.7, wall=596
2022-09-29 18:04:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:04:52 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.923 | nll_loss 5.519 | ppl 45.84 | wps 48392.3 | wpb 4813.2 | bsz 188.9 | num_updates 3454 | best_loss 6.923
2022-09-29 18:04:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 3454 updates
2022-09-29 18:04:52 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint11.pt
2022-09-29 18:04:54 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint11.pt
2022-09-29 18:04:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint11.pt (epoch 11 @ 3454 updates, score 6.923) (writing took 6.379366493085399 seconds)
2022-09-29 18:04:59 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-09-29 18:04:59 | INFO | train | epoch 011 | loss 6.626 | nll_loss 5.278 | ppl 38.81 | wps 19708.4 | ups 2.56 | wpb 7710.3 | bsz 302.2 | num_updates 3454 | lr 0.000863514 | gnorm 1.085 | train_wall 114 | gb_free 23.6 | wall 624
2022-09-29 18:04:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:04:59 | INFO | fairseq.trainer | begin training epoch 12
2022-09-29 18:04:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:05:16 | INFO | train_inner | epoch 012:     46 / 314 loss=6.45, nll_loss=5.075, ppl=33.72, wps=17714, ups=2.21, wpb=8027.1, bsz=308.4, num_updates=3500, lr=0.000875012, gnorm=0.956, train_wall=37, gb_free=23.5, wall=641
2022-09-29 18:05:53 | INFO | train_inner | epoch 012:    146 / 314 loss=6.425, nll_loss=5.041, ppl=32.91, wps=21109.2, ups=2.73, wpb=7746.1, bsz=305.3, num_updates=3600, lr=0.00090001, gnorm=1.068, train_wall=36, gb_free=23.6, wall=678
2022-09-29 18:06:30 | INFO | train_inner | epoch 012:    246 / 314 loss=6.435, nll_loss=5.049, ppl=33.1, wps=21286.4, ups=2.73, wpb=7797, bsz=313.4, num_updates=3700, lr=0.000925007, gnorm=0.98, train_wall=36, gb_free=23.7, wall=715
2022-09-29 18:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:06:56 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.998 | nll_loss 5.586 | ppl 48.03 | wps 48290.4 | wpb 4813.2 | bsz 188.9 | num_updates 3768 | best_loss 6.923
2022-09-29 18:06:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 3768 updates
2022-09-29 18:06:56 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint12.pt
2022-09-29 18:06:57 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint12.pt
2022-09-29 18:07:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint12.pt (epoch 12 @ 3768 updates, score 6.998) (writing took 3.8886089690495282 seconds)
2022-09-29 18:07:00 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-09-29 18:07:00 | INFO | train | epoch 012 | loss 6.431 | nll_loss 5.047 | ppl 33.05 | wps 20048.1 | ups 2.6 | wpb 7710.3 | bsz 302.2 | num_updates 3768 | lr 0.000942006 | gnorm 1.042 | train_wall 115 | gb_free 23.5 | wall 745
2022-09-29 18:07:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:07:00 | INFO | fairseq.trainer | begin training epoch 13
2022-09-29 18:07:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:07:12 | INFO | train_inner | epoch 013:     32 / 314 loss=6.453, nll_loss=5.071, ppl=33.61, wps=17696.7, ups=2.37, wpb=7453.5, bsz=274.3, num_updates=3800, lr=0.000950005, gnorm=1.123, train_wall=36, gb_free=24.7, wall=757
2022-09-29 18:07:48 | INFO | train_inner | epoch 013:    132 / 314 loss=6.221, nll_loss=4.801, ppl=27.88, wps=20126, ups=2.75, wpb=7307.1, bsz=303.9, num_updates=3900, lr=0.000975002, gnorm=1.095, train_wall=36, gb_free=23.9, wall=793
2022-09-29 18:08:25 | INFO | train_inner | epoch 013:    232 / 314 loss=6.344, nll_loss=4.937, ppl=30.63, wps=21557, ups=2.72, wpb=7930, bsz=306.7, num_updates=4000, lr=0.001, gnorm=1.025, train_wall=37, gb_free=23.5, wall=830
2022-09-29 18:08:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:08:56 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.931 | nll_loss 5.481 | ppl 44.67 | wps 48676.5 | wpb 4813.2 | bsz 188.9 | num_updates 4082 | best_loss 6.923
2022-09-29 18:08:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 4082 updates
2022-09-29 18:08:56 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint13.pt
2022-09-29 18:08:58 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint13.pt
2022-09-29 18:09:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint13.pt (epoch 13 @ 4082 updates, score 6.931) (writing took 4.16154277487658 seconds)
2022-09-29 18:09:00 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-09-29 18:09:00 | INFO | train | epoch 013 | loss 6.304 | nll_loss 4.895 | ppl 29.75 | wps 20069.5 | ups 2.6 | wpb 7710.3 | bsz 302.2 | num_updates 4082 | lr 0.000989905 | gnorm 1.035 | train_wall 114 | gb_free 23.6 | wall 865
2022-09-29 18:09:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:09:00 | INFO | fairseq.trainer | begin training epoch 14
2022-09-29 18:09:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:09:07 | INFO | train_inner | epoch 014:     18 / 314 loss=6.329, nll_loss=4.924, ppl=30.36, wps=18520.5, ups=2.36, wpb=7852.4, bsz=305.1, num_updates=4100, lr=0.00098773, gnorm=0.99, train_wall=36, gb_free=23.7, wall=872
2022-09-29 18:09:44 | INFO | train_inner | epoch 014:    118 / 314 loss=6.067, nll_loss=4.62, ppl=24.59, wps=21521.4, ups=2.72, wpb=7916.5, bsz=314.4, num_updates=4200, lr=0.0009759, gnorm=0.978, train_wall=37, gb_free=24.4, wall=909
2022-09-29 18:10:20 | INFO | train_inner | epoch 014:    218 / 314 loss=6.144, nll_loss=4.703, ppl=26.05, wps=20583.3, ups=2.75, wpb=7478.8, bsz=265.5, num_updates=4300, lr=0.000964486, gnorm=1.035, train_wall=36, gb_free=24, wall=945
2022-09-29 18:10:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:10:57 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.879 | nll_loss 5.437 | ppl 43.33 | wps 48087.4 | wpb 4813.2 | bsz 188.9 | num_updates 4396 | best_loss 6.879
2022-09-29 18:10:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 4396 updates
2022-09-29 18:10:57 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint14.pt
2022-09-29 18:10:59 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint14.pt
2022-09-29 18:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint14.pt (epoch 14 @ 4396 updates, score 6.879) (writing took 6.454761588945985 seconds)
2022-09-29 18:11:04 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-09-29 18:11:04 | INFO | train | epoch 014 | loss 6.12 | nll_loss 4.679 | ppl 25.62 | wps 19574.4 | ups 2.54 | wpb 7710.3 | bsz 302.2 | num_updates 4396 | lr 0.000953896 | gnorm 1.007 | train_wall 115 | gb_free 23.9 | wall 989
2022-09-29 18:11:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:11:04 | INFO | fairseq.trainer | begin training epoch 15
2022-09-29 18:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:11:06 | INFO | train_inner | epoch 015:      4 / 314 loss=6.164, nll_loss=4.728, ppl=26.51, wps=17229.6, ups=2.21, wpb=7790.8, bsz=319, num_updates=4400, lr=0.000953463, gnorm=0.985, train_wall=37, gb_free=24, wall=991
2022-09-29 18:11:42 | INFO | train_inner | epoch 015:    104 / 314 loss=5.771, nll_loss=4.277, ppl=19.38, wps=19548.9, ups=2.77, wpb=7057.6, bsz=280, num_updates=4500, lr=0.000942809, gnorm=1.002, train_wall=36, gb_free=23.8, wall=1027
2022-09-29 18:12:19 | INFO | train_inner | epoch 015:    204 / 314 loss=5.939, nll_loss=4.463, ppl=22.06, wps=21515.3, ups=2.71, wpb=7952.7, bsz=342.7, num_updates=4600, lr=0.000932505, gnorm=0.98, train_wall=37, gb_free=23.6, wall=1064
2022-09-29 18:12:56 | INFO | train_inner | epoch 015:    304 / 314 loss=6.012, nll_loss=4.549, ppl=23.41, wps=21416, ups=2.66, wpb=8045.4, bsz=286.2, num_updates=4700, lr=0.000922531, gnorm=0.948, train_wall=37, gb_free=23.7, wall=1101
2022-09-29 18:13:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:13:02 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.849 | nll_loss 5.369 | ppl 41.33 | wps 48402.2 | wpb 4813.2 | bsz 188.9 | num_updates 4710 | best_loss 6.849
2022-09-29 18:13:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 4710 updates
2022-09-29 18:13:02 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint15.pt
2022-09-29 18:13:03 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint15.pt
2022-09-29 18:13:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint15.pt (epoch 15 @ 4710 updates, score 6.849) (writing took 6.3880011171568185 seconds)
2022-09-29 18:13:08 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-09-29 18:13:08 | INFO | train | epoch 015 | loss 5.917 | nll_loss 4.441 | ppl 21.72 | wps 19525.3 | ups 2.53 | wpb 7710.3 | bsz 302.2 | num_updates 4710 | lr 0.000921551 | gnorm 0.971 | train_wall 115 | gb_free 23.5 | wall 1113
2022-09-29 18:13:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:13:08 | INFO | fairseq.trainer | begin training epoch 16
2022-09-29 18:13:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:13:42 | INFO | train_inner | epoch 016:     90 / 314 loss=5.651, nll_loss=4.134, ppl=17.56, wps=16750.9, ups=2.2, wpb=7600.9, bsz=275.3, num_updates=4800, lr=0.000912871, gnorm=0.944, train_wall=37, gb_free=24.7, wall=1147
2022-09-29 18:14:19 | INFO | train_inner | epoch 016:    190 / 314 loss=5.756, nll_loss=4.25, ppl=19.02, wps=21094.6, ups=2.69, wpb=7840.9, bsz=287.8, num_updates=4900, lr=0.000903508, gnorm=0.958, train_wall=37, gb_free=23.4, wall=1184
2022-09-29 18:14:56 | INFO | train_inner | epoch 016:    290 / 314 loss=5.809, nll_loss=4.312, ppl=19.86, wps=20882.7, ups=2.71, wpb=7701.6, bsz=338.1, num_updates=5000, lr=0.000894427, gnorm=1.013, train_wall=37, gb_free=24, wall=1221
2022-09-29 18:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:15:06 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.847 | nll_loss 5.352 | ppl 40.84 | wps 48357.6 | wpb 4813.2 | bsz 188.9 | num_updates 5024 | best_loss 6.847
2022-09-29 18:15:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 5024 updates
2022-09-29 18:15:06 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint16.pt
2022-09-29 18:15:08 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint16.pt
2022-09-29 18:15:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint16.pt (epoch 16 @ 5024 updates, score 6.847) (writing took 6.893973729806021 seconds)
2022-09-29 18:15:13 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-09-29 18:15:13 | INFO | train | epoch 016 | loss 5.738 | nll_loss 4.231 | ppl 18.78 | wps 19365.7 | ups 2.51 | wpb 7710.3 | bsz 302.2 | num_updates 5024 | lr 0.000892288 | gnorm 0.973 | train_wall 116 | gb_free 24 | wall 1238
2022-09-29 18:15:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:15:13 | INFO | fairseq.trainer | begin training epoch 17
2022-09-29 18:15:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:15:41 | INFO | train_inner | epoch 017:     76 / 314 loss=5.534, nll_loss=3.994, ppl=15.93, wps=16598.7, ups=2.23, wpb=7445.1, bsz=290.6, num_updates=5100, lr=0.000885615, gnorm=0.987, train_wall=36, gb_free=24.8, wall=1265
2022-09-29 18:16:17 | INFO | train_inner | epoch 017:    176 / 314 loss=5.598, nll_loss=4.063, ppl=16.72, wps=21562.1, ups=2.73, wpb=7897, bsz=298.5, num_updates=5200, lr=0.000877058, gnorm=0.982, train_wall=36, gb_free=23.7, wall=1302
2022-09-29 18:16:54 | INFO | train_inner | epoch 017:    276 / 314 loss=5.644, nll_loss=4.116, ppl=17.34, wps=20684.5, ups=2.73, wpb=7578.2, bsz=308.2, num_updates=5300, lr=0.000868744, gnorm=0.986, train_wall=36, gb_free=23.8, wall=1339
2022-09-29 18:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:17:09 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.803 | nll_loss 5.301 | ppl 39.42 | wps 47628.3 | wpb 4813.2 | bsz 188.9 | num_updates 5338 | best_loss 6.803
2022-09-29 18:17:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 5338 updates
2022-09-29 18:17:09 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint17.pt
2022-09-29 18:17:11 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint17.pt
2022-09-29 18:17:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint17.pt (epoch 17 @ 5338 updates, score 6.803) (writing took 6.366018465952948 seconds)
2022-09-29 18:17:16 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-09-29 18:17:16 | INFO | train | epoch 017 | loss 5.585 | nll_loss 4.05 | ppl 16.56 | wps 19708.1 | ups 2.56 | wpb 7710.3 | bsz 302.2 | num_updates 5338 | lr 0.000865647 | gnorm 0.974 | train_wall 114 | gb_free 24.4 | wall 1361
2022-09-29 18:17:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:17:16 | INFO | fairseq.trainer | begin training epoch 18
2022-09-29 18:17:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:17:39 | INFO | train_inner | epoch 018:     62 / 314 loss=5.432, nll_loss=3.872, ppl=14.64, wps=17654.6, ups=2.23, wpb=7922, bsz=337.6, num_updates=5400, lr=0.000860663, gnorm=0.964, train_wall=37, gb_free=23.7, wall=1384
2022-09-29 18:18:15 | INFO | train_inner | epoch 018:    162 / 314 loss=5.408, nll_loss=3.839, ppl=14.31, wps=21602.1, ups=2.72, wpb=7927.5, bsz=301.2, num_updates=5500, lr=0.000852803, gnorm=0.973, train_wall=36, gb_free=24.4, wall=1420
2022-09-29 18:18:52 | INFO | train_inner | epoch 018:    262 / 314 loss=5.492, nll_loss=3.936, ppl=15.31, wps=20747.7, ups=2.74, wpb=7563.1, bsz=294.2, num_updates=5600, lr=0.000845154, gnorm=1.005, train_wall=36, gb_free=24.2, wall=1457
2022-09-29 18:19:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:19:12 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.809 | nll_loss 5.297 | ppl 39.33 | wps 48239.8 | wpb 4813.2 | bsz 188.9 | num_updates 5652 | best_loss 6.803
2022-09-29 18:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 5652 updates
2022-09-29 18:19:12 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint18.pt
2022-09-29 18:19:14 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint18.pt
2022-09-29 18:19:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint18.pt (epoch 18 @ 5652 updates, score 6.809) (writing took 3.9464188599959016 seconds)
2022-09-29 18:19:16 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-09-29 18:19:16 | INFO | train | epoch 018 | loss 5.433 | nll_loss 3.87 | ppl 14.62 | wps 20089.5 | ups 2.61 | wpb 7710.3 | bsz 302.2 | num_updates 5652 | lr 0.000841257 | gnorm 0.989 | train_wall 114 | gb_free 23.8 | wall 1481
2022-09-29 18:19:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:19:16 | INFO | fairseq.trainer | begin training epoch 19
2022-09-29 18:19:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:19:34 | INFO | train_inner | epoch 019:     48 / 314 loss=5.373, nll_loss=3.801, ppl=13.94, wps=17957.3, ups=2.38, wpb=7560, bsz=273.3, num_updates=5700, lr=0.000837708, gnorm=0.97, train_wall=36, gb_free=25, wall=1499
2022-09-29 18:20:11 | INFO | train_inner | epoch 019:    148 / 314 loss=5.243, nll_loss=3.645, ppl=12.51, wps=21078.5, ups=2.7, wpb=7800.4, bsz=320.9, num_updates=5800, lr=0.000830455, gnorm=0.979, train_wall=37, gb_free=23.8, wall=1536
2022-09-29 18:20:47 | INFO | train_inner | epoch 019:    248 / 314 loss=5.352, nll_loss=3.771, ppl=13.65, wps=21705.4, ups=2.77, wpb=7821.9, bsz=319.4, num_updates=5900, lr=0.000823387, gnorm=0.993, train_wall=36, gb_free=24.1, wall=1572
2022-09-29 18:21:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:21:12 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 6.863 | nll_loss 5.355 | ppl 40.93 | wps 47986.1 | wpb 4813.2 | bsz 188.9 | num_updates 5966 | best_loss 6.803
2022-09-29 18:21:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 5966 updates
2022-09-29 18:21:12 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint19.pt
2022-09-29 18:21:14 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint19.pt
2022-09-29 18:21:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint19.pt (epoch 19 @ 5966 updates, score 6.863) (writing took 4.056784748099744 seconds)
2022-09-29 18:21:16 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-09-29 18:21:16 | INFO | train | epoch 019 | loss 5.304 | nll_loss 3.717 | ppl 13.15 | wps 20192.4 | ups 2.62 | wpb 7710.3 | bsz 302.2 | num_updates 5966 | lr 0.00081882 | gnorm 0.994 | train_wall 114 | gb_free 23.9 | wall 1601
2022-09-29 18:21:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:21:16 | INFO | fairseq.trainer | begin training epoch 20
2022-09-29 18:21:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:21:29 | INFO | train_inner | epoch 020:     34 / 314 loss=5.315, nll_loss=3.731, ppl=13.28, wps=18669.3, ups=2.39, wpb=7827.3, bsz=267.8, num_updates=6000, lr=0.000816497, gnorm=0.992, train_wall=36, gb_free=23.8, wall=1614
2022-09-29 18:22:05 | INFO | train_inner | epoch 020:    134 / 314 loss=5.122, nll_loss=3.504, ppl=11.34, wps=21114.6, ups=2.78, wpb=7591.2, bsz=286.7, num_updates=6100, lr=0.000809776, gnorm=0.99, train_wall=36, gb_free=24, wall=1650
2022-09-29 18:22:41 | INFO | train_inner | epoch 020:    234 / 314 loss=5.187, nll_loss=3.578, ppl=11.95, wps=21658.2, ups=2.74, wpb=7905.4, bsz=340.5, num_updates=6200, lr=0.000803219, gnorm=0.996, train_wall=36, gb_free=24, wall=1686
2022-09-29 18:23:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:23:11 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 6.869 | nll_loss 5.343 | ppl 40.58 | wps 48441 | wpb 4813.2 | bsz 188.9 | num_updates 6280 | best_loss 6.803
2022-09-29 18:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 6280 updates
2022-09-29 18:23:11 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint20.pt
2022-09-29 18:23:13 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint20.pt
2022-09-29 18:23:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint20.pt (epoch 20 @ 6280 updates, score 6.869) (writing took 4.2898024681489915 seconds)
2022-09-29 18:23:16 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-09-29 18:23:16 | INFO | train | epoch 020 | loss 5.183 | nll_loss 3.574 | ppl 11.91 | wps 20254.8 | ups 2.63 | wpb 7710.3 | bsz 302.2 | num_updates 6280 | lr 0.000798087 | gnorm 0.994 | train_wall 113 | gb_free 23.6 | wall 1721
2022-09-29 18:23:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:23:16 | INFO | fairseq.trainer | begin training epoch 21
2022-09-29 18:23:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:23:24 | INFO | train_inner | epoch 021:     20 / 314 loss=5.208, nll_loss=3.602, ppl=12.14, wps=17635.5, ups=2.37, wpb=7428, bsz=305.8, num_updates=6300, lr=0.000796819, gnorm=1.003, train_wall=36, gb_free=23.7, wall=1728
2022-09-29 18:24:00 | INFO | train_inner | epoch 021:    120 / 314 loss=4.991, nll_loss=3.348, ppl=10.18, wps=21737.3, ups=2.74, wpb=7926.5, bsz=275.7, num_updates=6400, lr=0.000790569, gnorm=0.928, train_wall=36, gb_free=23.8, wall=1765
2022-09-29 18:24:36 | INFO | train_inner | epoch 021:    220 / 314 loss=5.098, nll_loss=3.472, ppl=11.1, wps=21377.2, ups=2.74, wpb=7802.3, bsz=318.8, num_updates=6500, lr=0.000784465, gnorm=1.013, train_wall=36, gb_free=24.1, wall=1801
2022-09-29 18:25:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:25:11 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 6.861 | nll_loss 5.333 | ppl 40.32 | wps 48233.9 | wpb 4813.2 | bsz 188.9 | num_updates 6594 | best_loss 6.803
2022-09-29 18:25:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 6594 updates
2022-09-29 18:25:11 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint21.pt
2022-09-29 18:25:13 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint21.pt
2022-09-29 18:25:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint21.pt (epoch 21 @ 6594 updates, score 6.861) (writing took 4.206367264036089 seconds)
2022-09-29 18:25:16 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-09-29 18:25:16 | INFO | train | epoch 021 | loss 5.072 | nll_loss 3.443 | ppl 10.87 | wps 20197.5 | ups 2.62 | wpb 7710.3 | bsz 302.2 | num_updates 6594 | lr 0.000778853 | gnorm 0.996 | train_wall 113 | gb_free 23.7 | wall 1840
2022-09-29 18:25:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:25:16 | INFO | fairseq.trainer | begin training epoch 22
2022-09-29 18:25:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:25:18 | INFO | train_inner | epoch 022:      6 / 314 loss=5.159, nll_loss=3.544, ppl=11.67, wps=17865.7, ups=2.4, wpb=7445.9, bsz=309.4, num_updates=6600, lr=0.000778499, gnorm=1.062, train_wall=36, gb_free=24.1, wall=1843
2022-09-29 18:25:55 | INFO | train_inner | epoch 022:    106 / 314 loss=4.859, nll_loss=3.193, ppl=9.15, wps=21555.9, ups=2.75, wpb=7847.7, bsz=311.5, num_updates=6700, lr=0.000772667, gnorm=0.997, train_wall=36, gb_free=27, wall=1879
2022-09-29 18:26:31 | INFO | train_inner | epoch 022:    206 / 314 loss=4.979, nll_loss=3.331, ppl=10.07, wps=21055, ups=2.77, wpb=7609.3, bsz=258.6, num_updates=6800, lr=0.000766965, gnorm=0.981, train_wall=36, gb_free=24.6, wall=1916
2022-09-29 18:27:07 | INFO | train_inner | epoch 022:    306 / 314 loss=5.085, nll_loss=3.455, ppl=10.96, wps=21092, ups=2.77, wpb=7616.6, bsz=313.7, num_updates=6900, lr=0.000761387, gnorm=1.061, train_wall=36, gb_free=23.8, wall=1952
2022-09-29 18:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:27:11 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 6.881 | nll_loss 5.346 | ppl 40.66 | wps 48247.2 | wpb 4813.2 | bsz 188.9 | num_updates 6908 | best_loss 6.803
2022-09-29 18:27:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 6908 updates
2022-09-29 18:27:11 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint22.pt
2022-09-29 18:27:13 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint22.pt
2022-09-29 18:27:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint22.pt (epoch 22 @ 6908 updates, score 6.881) (writing took 3.9838932082057 seconds)
2022-09-29 18:27:15 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-09-29 18:27:15 | INFO | train | epoch 022 | loss 4.97 | nll_loss 3.322 | ppl 10 | wps 20253.5 | ups 2.63 | wpb 7710.3 | bsz 302.2 | num_updates 6908 | lr 0.000760946 | gnorm 1.013 | train_wall 113 | gb_free 23.7 | wall 1960
2022-09-29 18:27:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:27:15 | INFO | fairseq.trainer | begin training epoch 23
2022-09-29 18:27:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:27:49 | INFO | train_inner | epoch 023:     92 / 314 loss=4.74, nll_loss=3.055, ppl=8.31, wps=18091.3, ups=2.35, wpb=7711, bsz=300.5, num_updates=7000, lr=0.000755929, gnorm=0.985, train_wall=37, gb_free=24, wall=1994
2022-09-29 18:28:26 | INFO | train_inner | epoch 023:    192 / 314 loss=4.872, nll_loss=3.206, ppl=9.23, wps=20628.8, ups=2.74, wpb=7519.6, bsz=291.1, num_updates=7100, lr=0.000750587, gnorm=1.045, train_wall=36, gb_free=23.7, wall=2031
2022-09-29 18:29:03 | INFO | train_inner | epoch 023:    292 / 314 loss=4.979, nll_loss=3.331, ppl=10.07, wps=21429.3, ups=2.73, wpb=7851.8, bsz=324.1, num_updates=7200, lr=0.000745356, gnorm=1.025, train_wall=36, gb_free=29.4, wall=2067
2022-09-29 18:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:29:12 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 6.981 | nll_loss 5.45 | ppl 43.71 | wps 47653.3 | wpb 4813.2 | bsz 188.9 | num_updates 7222 | best_loss 6.803
2022-09-29 18:29:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 7222 updates
2022-09-29 18:29:12 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint23.pt
2022-09-29 18:29:14 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint23.pt
2022-09-29 18:29:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint23.pt (epoch 23 @ 7222 updates, score 6.981) (writing took 4.258388828951865 seconds)
2022-09-29 18:29:17 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-09-29 18:29:17 | INFO | train | epoch 023 | loss 4.879 | nll_loss 3.215 | ppl 9.29 | wps 19948.3 | ups 2.59 | wpb 7710.3 | bsz 302.2 | num_updates 7222 | lr 0.00074422 | gnorm 1.021 | train_wall 115 | gb_free 24.1 | wall 2081
2022-09-29 18:29:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:29:17 | INFO | fairseq.trainer | begin training epoch 24
2022-09-29 18:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:29:46 | INFO | train_inner | epoch 024:     78 / 314 loss=4.75, nll_loss=3.064, ppl=8.37, wps=18422.2, ups=2.31, wpb=7962.9, bsz=324.7, num_updates=7300, lr=0.000740233, gnorm=1.01, train_wall=37, gb_free=23.6, wall=2111
2022-09-29 18:30:22 | INFO | train_inner | epoch 024:    178 / 314 loss=4.765, nll_loss=3.081, ppl=8.46, wps=20830.9, ups=2.72, wpb=7650.4, bsz=293.4, num_updates=7400, lr=0.000735215, gnorm=1.024, train_wall=36, gb_free=24.1, wall=2147
2022-09-29 18:30:59 | INFO | train_inner | epoch 024:    278 / 314 loss=4.888, nll_loss=3.223, ppl=9.34, wps=20916.1, ups=2.76, wpb=7578.9, bsz=296.9, num_updates=7500, lr=0.000730297, gnorm=1.08, train_wall=36, gb_free=23.6, wall=2184
2022-09-29 18:31:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:31:13 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 6.931 | nll_loss 5.392 | ppl 41.99 | wps 47870.7 | wpb 4813.2 | bsz 188.9 | num_updates 7536 | best_loss 6.803
2022-09-29 18:31:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 7536 updates
2022-09-29 18:31:13 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint24.pt
2022-09-29 18:31:15 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint24.pt
2022-09-29 18:31:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint24.pt (epoch 24 @ 7536 updates, score 6.931) (writing took 3.954971756087616 seconds)
2022-09-29 18:31:17 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-09-29 18:31:17 | INFO | train | epoch 024 | loss 4.789 | nll_loss 3.109 | ppl 8.63 | wps 20015.5 | ups 2.6 | wpb 7710.3 | bsz 302.2 | num_updates 7536 | lr 0.00072855 | gnorm 1.028 | train_wall 115 | gb_free 23.7 | wall 2202
2022-09-29 18:31:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:31:17 | INFO | fairseq.trainer | begin training epoch 25
2022-09-29 18:31:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:31:41 | INFO | train_inner | epoch 025:     64 / 314 loss=4.677, nll_loss=2.979, ppl=7.88, wps=18389.6, ups=2.34, wpb=7856.8, bsz=301.6, num_updates=7600, lr=0.000725476, gnorm=0.965, train_wall=37, gb_free=24.8, wall=2226
2022-09-29 18:32:18 | INFO | train_inner | epoch 025:    164 / 314 loss=4.655, nll_loss=2.952, ppl=7.74, wps=21197.3, ups=2.77, wpb=7641.7, bsz=274.6, num_updates=7700, lr=0.00072075, gnorm=0.98, train_wall=36, gb_free=23.4, wall=2262
2022-09-29 18:32:54 | INFO | train_inner | epoch 025:    264 / 314 loss=4.756, nll_loss=3.067, ppl=8.38, wps=20235.1, ups=2.77, wpb=7316.8, bsz=319.5, num_updates=7800, lr=0.000716115, gnorm=1.095, train_wall=36, gb_free=23.6, wall=2299
2022-09-29 18:33:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:33:13 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 6.939 | nll_loss 5.398 | ppl 42.17 | wps 47353 | wpb 4813.2 | bsz 188.9 | num_updates 7850 | best_loss 6.803
2022-09-29 18:33:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 7850 updates
2022-09-29 18:33:13 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint25.pt
2022-09-29 18:33:15 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint25.pt
2022-09-29 18:33:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint25.pt (epoch 25 @ 7850 updates, score 6.939) (writing took 4.082148033194244 seconds)
2022-09-29 18:33:18 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-09-29 18:33:18 | INFO | train | epoch 025 | loss 4.704 | nll_loss 3.009 | ppl 8.05 | wps 20154.2 | ups 2.61 | wpb 7710.3 | bsz 302.2 | num_updates 7850 | lr 0.000713831 | gnorm 1.016 | train_wall 113 | gb_free 24.6 | wall 2322
2022-09-29 18:33:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:33:18 | INFO | fairseq.trainer | begin training epoch 26
2022-09-29 18:33:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:33:36 | INFO | train_inner | epoch 026:     50 / 314 loss=4.694, nll_loss=3, ppl=8, wps=18836.5, ups=2.38, wpb=7925.6, bsz=293.4, num_updates=7900, lr=0.000711568, gnorm=1.004, train_wall=36, gb_free=24, wall=2341
2022-09-29 18:34:13 | INFO | train_inner | epoch 026:    150 / 314 loss=4.541, nll_loss=2.818, ppl=7.05, wps=21059, ups=2.71, wpb=7759.6, bsz=310.1, num_updates=8000, lr=0.000707107, gnorm=1.05, train_wall=36, gb_free=27, wall=2377
2022-09-29 18:34:50 | INFO | train_inner | epoch 026:    250 / 314 loss=4.683, nll_loss=2.984, ppl=7.91, wps=20974.7, ups=2.68, wpb=7823.5, bsz=312.6, num_updates=8100, lr=0.000702728, gnorm=1.015, train_wall=37, gb_free=24, wall=2415
2022-09-29 18:35:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:35:14 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 6.997 | nll_loss 5.464 | ppl 44.14 | wps 47965.7 | wpb 4813.2 | bsz 188.9 | num_updates 8164 | best_loss 6.803
2022-09-29 18:35:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 8164 updates
2022-09-29 18:35:14 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint26.pt
2022-09-29 18:35:16 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint26.pt
2022-09-29 18:35:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint26.pt (epoch 26 @ 8164 updates, score 6.997) (writing took 3.966953822877258 seconds)
2022-09-29 18:35:18 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-09-29 18:35:18 | INFO | train | epoch 026 | loss 4.631 | nll_loss 2.923 | ppl 7.58 | wps 20074.6 | ups 2.6 | wpb 7710.3 | bsz 302.2 | num_updates 8164 | lr 0.000699969 | gnorm 1.055 | train_wall 114 | gb_free 23.5 | wall 2443
2022-09-29 18:35:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:35:18 | INFO | fairseq.trainer | begin training epoch 27
2022-09-29 18:35:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:35:31 | INFO | train_inner | epoch 027:     36 / 314 loss=4.664, nll_loss=2.961, ppl=7.79, wps=18445.5, ups=2.41, wpb=7666.2, bsz=271.1, num_updates=8200, lr=0.00069843, gnorm=1.084, train_wall=36, gb_free=23.6, wall=2456
2022-09-29 18:36:08 | INFO | train_inner | epoch 027:    136 / 314 loss=4.449, nll_loss=2.711, ppl=6.55, wps=21331.6, ups=2.73, wpb=7806.9, bsz=313.8, num_updates=8300, lr=0.00069421, gnorm=1.002, train_wall=36, gb_free=24.1, wall=2493
2022-09-29 18:36:45 | INFO | train_inner | epoch 027:    236 / 314 loss=4.602, nll_loss=2.888, ppl=7.4, wps=21010.5, ups=2.7, wpb=7795.8, bsz=353.4, num_updates=8400, lr=0.000690066, gnorm=1.118, train_wall=37, gb_free=23.8, wall=2530
2022-09-29 18:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:37:14 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 6.987 | nll_loss 5.456 | ppl 43.89 | wps 48205.8 | wpb 4813.2 | bsz 188.9 | num_updates 8478 | best_loss 6.803
2022-09-29 18:37:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 8478 updates
2022-09-29 18:37:14 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint27.pt
2022-09-29 18:37:16 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint27.pt
2022-09-29 18:37:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint27.pt (epoch 27 @ 8478 updates, score 6.987) (writing took 4.171629365067929 seconds)
2022-09-29 18:37:19 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-09-29 18:37:19 | INFO | train | epoch 027 | loss 4.559 | nll_loss 2.839 | ppl 7.15 | wps 20107.7 | ups 2.61 | wpb 7710.3 | bsz 302.2 | num_updates 8478 | lr 0.000686884 | gnorm 1.061 | train_wall 114 | gb_free 23.6 | wall 2563
2022-09-29 18:37:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:37:19 | INFO | fairseq.trainer | begin training epoch 28
2022-09-29 18:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:37:27 | INFO | train_inner | epoch 028:     22 / 314 loss=4.604, nll_loss=2.891, ppl=7.42, wps=17905.6, ups=2.4, wpb=7452, bsz=281.2, num_updates=8500, lr=0.000685994, gnorm=1.082, train_wall=36, gb_free=23.7, wall=2572
2022-09-29 18:38:03 | INFO | train_inner | epoch 028:    122 / 314 loss=4.4, nll_loss=2.652, ppl=6.28, wps=21333.5, ups=2.77, wpb=7692.4, bsz=291, num_updates=8600, lr=0.000681994, gnorm=1.031, train_wall=36, gb_free=23.8, wall=2608
2022-09-29 18:38:39 | INFO | train_inner | epoch 028:    222 / 314 loss=4.478, nll_loss=2.745, ppl=6.7, wps=20424.6, ups=2.78, wpb=7339.9, bsz=284.8, num_updates=8700, lr=0.000678064, gnorm=1.061, train_wall=36, gb_free=24.4, wall=2644
2022-09-29 18:39:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:39:14 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.007 | nll_loss 5.472 | ppl 44.39 | wps 48188.7 | wpb 4813.2 | bsz 188.9 | num_updates 8792 | best_loss 6.803
2022-09-29 18:39:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 8792 updates
2022-09-29 18:39:14 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint28.pt
2022-09-29 18:39:16 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint28.pt
2022-09-29 18:39:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint28.pt (epoch 28 @ 8792 updates, score 7.007) (writing took 3.922656901180744 seconds)
2022-09-29 18:39:18 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-09-29 18:39:18 | INFO | train | epoch 028 | loss 4.488 | nll_loss 2.756 | ppl 6.76 | wps 20249.4 | ups 2.63 | wpb 7710.3 | bsz 302.2 | num_updates 8792 | lr 0.000674507 | gnorm 1.035 | train_wall 113 | gb_free 24.3 | wall 2683
2022-09-29 18:39:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:39:18 | INFO | fairseq.trainer | begin training epoch 29
2022-09-29 18:39:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:39:21 | INFO | train_inner | epoch 029:      8 / 314 loss=4.622, nll_loss=2.914, ppl=7.54, wps=19292.5, ups=2.35, wpb=8194.4, bsz=309.8, num_updates=8800, lr=0.0006742, gnorm=1.016, train_wall=37, gb_free=24, wall=2686
2022-09-29 18:39:58 | INFO | train_inner | epoch 029:    108 / 314 loss=4.332, nll_loss=2.574, ppl=5.96, wps=21186.4, ups=2.71, wpb=7811.7, bsz=290.5, num_updates=8900, lr=0.000670402, gnorm=1.037, train_wall=37, gb_free=24.3, wall=2723
2022-09-29 18:40:35 | INFO | train_inner | epoch 029:    208 / 314 loss=4.391, nll_loss=2.641, ppl=6.24, wps=20855, ups=2.69, wpb=7751.6, bsz=345, num_updates=9000, lr=0.000666667, gnorm=1.063, train_wall=37, gb_free=23.7, wall=2760
2022-09-29 18:41:12 | INFO | train_inner | epoch 029:    308 / 314 loss=4.541, nll_loss=2.818, ppl=7.05, wps=20782, ups=2.73, wpb=7607.6, bsz=284.5, num_updates=9100, lr=0.000662994, gnorm=1.073, train_wall=36, gb_free=23.6, wall=2797
2022-09-29 18:41:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:41:15 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.064 | nll_loss 5.538 | ppl 46.47 | wps 48384.5 | wpb 4813.2 | bsz 188.9 | num_updates 9106 | best_loss 6.803
2022-09-29 18:41:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 9106 updates
2022-09-29 18:41:15 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint29.pt
2022-09-29 18:41:17 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint29.pt
2022-09-29 18:41:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint29.pt (epoch 29 @ 9106 updates, score 7.064) (writing took 4.148655628785491 seconds)
2022-09-29 18:41:20 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-09-29 18:41:20 | INFO | train | epoch 029 | loss 4.419 | nll_loss 2.676 | ppl 6.39 | wps 19944.4 | ups 2.59 | wpb 7710.3 | bsz 302.2 | num_updates 9106 | lr 0.000662775 | gnorm 1.056 | train_wall 115 | gb_free 23.7 | wall 2804
2022-09-29 18:41:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:41:20 | INFO | fairseq.trainer | begin training epoch 30
2022-09-29 18:41:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:41:54 | INFO | train_inner | epoch 030:     94 / 314 loss=4.216, nll_loss=2.436, ppl=5.41, wps=17105.9, ups=2.39, wpb=7161.9, bsz=276, num_updates=9200, lr=0.00065938, gnorm=1.081, train_wall=36, gb_free=24.1, wall=2839
2022-09-29 18:42:31 | INFO | train_inner | epoch 030:    194 / 314 loss=4.353, nll_loss=2.599, ppl=6.06, wps=20871.6, ups=2.67, wpb=7822.3, bsz=325.9, num_updates=9300, lr=0.000655826, gnorm=1.046, train_wall=37, gb_free=24.1, wall=2876
2022-09-29 18:43:08 | INFO | train_inner | epoch 030:    294 / 314 loss=4.494, nll_loss=2.765, ppl=6.8, wps=21356.3, ups=2.69, wpb=7932.4, bsz=292, num_updates=9400, lr=0.000652328, gnorm=1.06, train_wall=37, gb_free=23.5, wall=2913
2022-09-29 18:43:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:43:17 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.021 | nll_loss 5.493 | ppl 45.04 | wps 48511 | wpb 4813.2 | bsz 188.9 | num_updates 9420 | best_loss 6.803
2022-09-29 18:43:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 9420 updates
2022-09-29 18:43:17 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint30.pt
2022-09-29 18:43:19 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint30.pt
2022-09-29 18:43:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint30.pt (epoch 30 @ 9420 updates, score 7.021) (writing took 4.129841921152547 seconds)
2022-09-29 18:43:21 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-09-29 18:43:21 | INFO | train | epoch 030 | loss 4.368 | nll_loss 2.617 | ppl 6.13 | wps 19850.7 | ups 2.57 | wpb 7710.3 | bsz 302.2 | num_updates 9420 | lr 0.000651635 | gnorm 1.055 | train_wall 115 | gb_free 24.2 | wall 2926
2022-09-29 18:43:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:43:22 | INFO | fairseq.trainer | begin training epoch 31
2022-09-29 18:43:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:43:52 | INFO | train_inner | epoch 031:     80 / 314 loss=4.258, nll_loss=2.487, ppl=5.61, wps=18528.6, ups=2.29, wpb=8100.9, bsz=326.1, num_updates=9500, lr=0.000648886, gnorm=0.988, train_wall=38, gb_free=24.4, wall=2957
2022-09-29 18:44:29 | INFO | train_inner | epoch 031:    180 / 314 loss=4.263, nll_loss=2.491, ppl=5.62, wps=21039.5, ups=2.7, wpb=7780.6, bsz=333.7, num_updates=9600, lr=0.000645497, gnorm=1.075, train_wall=37, gb_free=24.2, wall=2994
2022-09-29 18:45:06 | INFO | train_inner | epoch 031:    280 / 314 loss=4.398, nll_loss=2.651, ppl=6.28, wps=20549.9, ups=2.69, wpb=7649, bsz=265, num_updates=9700, lr=0.000642161, gnorm=1.078, train_wall=37, gb_free=24.2, wall=3031
2022-09-29 18:45:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:45:20 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.167 | nll_loss 5.637 | ppl 49.77 | wps 48108.1 | wpb 4813.2 | bsz 188.9 | num_updates 9734 | best_loss 6.803
2022-09-29 18:45:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 9734 updates
2022-09-29 18:45:20 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint31.pt
2022-09-29 18:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint31.pt
2022-09-29 18:45:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint31.pt (epoch 31 @ 9734 updates, score 7.167) (writing took 3.973518550163135 seconds)
2022-09-29 18:45:24 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-09-29 18:45:24 | INFO | train | epoch 031 | loss 4.297 | nll_loss 2.532 | ppl 5.78 | wps 19784.7 | ups 2.57 | wpb 7710.3 | bsz 302.2 | num_updates 9734 | lr 0.000641039 | gnorm 1.057 | train_wall 116 | gb_free 24.4 | wall 3049
2022-09-29 18:45:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:45:24 | INFO | fairseq.trainer | begin training epoch 32
2022-09-29 18:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:45:49 | INFO | train_inner | epoch 032:     66 / 314 loss=4.22, nll_loss=2.443, ppl=5.44, wps=17057, ups=2.36, wpb=7212.5, bsz=248.1, num_updates=9800, lr=0.000638877, gnorm=1.064, train_wall=37, gb_free=23.4, wall=3073
2022-09-29 18:46:25 | INFO | train_inner | epoch 032:    166 / 314 loss=4.242, nll_loss=2.471, ppl=5.54, wps=21178.2, ups=2.73, wpb=7759.9, bsz=281.3, num_updates=9900, lr=0.000635642, gnorm=1.084, train_wall=36, gb_free=24, wall=3110
2022-09-29 18:47:03 | INFO | train_inner | epoch 032:    266 / 314 loss=4.28, nll_loss=2.513, ppl=5.71, wps=20924.1, ups=2.67, wpb=7833.6, bsz=350.7, num_updates=10000, lr=0.000632456, gnorm=1.089, train_wall=37, gb_free=23.6, wall=3148
2022-09-29 18:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:47:22 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.097 | nll_loss 5.571 | ppl 47.53 | wps 48160.4 | wpb 4813.2 | bsz 188.9 | num_updates 10048 | best_loss 6.803
2022-09-29 18:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 10048 updates
2022-09-29 18:47:22 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint32.pt
2022-09-29 18:47:24 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint32.pt
2022-09-29 18:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint32.pt (epoch 32 @ 10048 updates, score 7.097) (writing took 3.9614320769906044 seconds)
2022-09-29 18:47:26 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-09-29 18:47:26 | INFO | train | epoch 032 | loss 4.258 | nll_loss 2.488 | ppl 5.61 | wps 19867.9 | ups 2.58 | wpb 7710.3 | bsz 302.2 | num_updates 10048 | lr 0.000630943 | gnorm 1.086 | train_wall 116 | gb_free 23.7 | wall 3171
2022-09-29 18:47:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:47:26 | INFO | fairseq.trainer | begin training epoch 33
2022-09-29 18:47:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:47:46 | INFO | train_inner | epoch 033:     52 / 314 loss=4.207, nll_loss=2.427, ppl=5.38, wps=18532, ups=2.33, wpb=7948, bsz=330, num_updates=10100, lr=0.000629317, gnorm=1.07, train_wall=37, gb_free=23.8, wall=3190
2022-09-29 18:48:21 | INFO | train_inner | epoch 033:    152 / 314 loss=4.143, nll_loss=2.352, ppl=5.11, wps=20609.3, ups=2.78, wpb=7401.4, bsz=282.6, num_updates=10200, lr=0.000626224, gnorm=1.089, train_wall=36, gb_free=26.9, wall=3226
2022-09-29 18:48:58 | INFO | train_inner | epoch 033:    252 / 314 loss=4.252, nll_loss=2.482, ppl=5.59, wps=20812.1, ups=2.75, wpb=7580.2, bsz=274.5, num_updates=10300, lr=0.000623177, gnorm=1.07, train_wall=36, gb_free=24.7, wall=3263
2022-09-29 18:49:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:49:22 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.125 | nll_loss 5.6 | ppl 48.49 | wps 48213.4 | wpb 4813.2 | bsz 188.9 | num_updates 10362 | best_loss 6.803
2022-09-29 18:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 10362 updates
2022-09-29 18:49:22 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint33.pt
2022-09-29 18:49:24 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint33.pt
2022-09-29 18:49:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint33.pt (epoch 33 @ 10362 updates, score 7.125) (writing took 3.846198556944728 seconds)
2022-09-29 18:49:26 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-09-29 18:49:26 | INFO | train | epoch 033 | loss 4.199 | nll_loss 2.419 | ppl 5.35 | wps 20091.9 | ups 2.61 | wpb 7710.3 | bsz 302.2 | num_updates 10362 | lr 0.00062131 | gnorm 1.067 | train_wall 114 | gb_free 23.5 | wall 3291
2022-09-29 18:49:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:49:26 | INFO | fairseq.trainer | begin training epoch 34
2022-09-29 18:49:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:49:40 | INFO | train_inner | epoch 034:     38 / 314 loss=4.201, nll_loss=2.421, ppl=5.36, wps=18782.2, ups=2.36, wpb=7973.3, bsz=346.9, num_updates=10400, lr=0.000620174, gnorm=1.061, train_wall=37, gb_free=23.5, wall=3305
2022-09-29 18:50:17 | INFO | train_inner | epoch 034:    138 / 314 loss=4.062, nll_loss=2.258, ppl=4.78, wps=19745.5, ups=2.71, wpb=7285.1, bsz=258.7, num_updates=10500, lr=0.000617213, gnorm=1.109, train_wall=37, gb_free=23.7, wall=3342
2022-09-29 18:50:54 | INFO | train_inner | epoch 034:    238 / 314 loss=4.193, nll_loss=2.414, ppl=5.33, wps=21369.6, ups=2.72, wpb=7847.7, bsz=311.7, num_updates=10600, lr=0.000614295, gnorm=1.054, train_wall=36, gb_free=24.1, wall=3379
2022-09-29 18:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:51:23 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.141 | nll_loss 5.614 | ppl 48.97 | wps 48269.9 | wpb 4813.2 | bsz 188.9 | num_updates 10676 | best_loss 6.803
2022-09-29 18:51:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 10676 updates
2022-09-29 18:51:23 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint34.pt
2022-09-29 18:51:25 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint34.pt
2022-09-29 18:51:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint34.pt (epoch 34 @ 10676 updates, score 7.141) (writing took 4.3416752750054 seconds)
2022-09-29 18:51:28 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-09-29 18:51:28 | INFO | train | epoch 034 | loss 4.155 | nll_loss 2.368 | ppl 5.16 | wps 19932.6 | ups 2.59 | wpb 7710.3 | bsz 302.2 | num_updates 10676 | lr 0.000612105 | gnorm 1.083 | train_wall 115 | gb_free 23.7 | wall 3413
2022-09-29 18:51:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:51:28 | INFO | fairseq.trainer | begin training epoch 35
2022-09-29 18:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:51:36 | INFO | train_inner | epoch 035:     24 / 314 loss=4.216, nll_loss=2.44, ppl=5.43, wps=18741.1, ups=2.35, wpb=7961, bsz=333.5, num_updates=10700, lr=0.000611418, gnorm=1.088, train_wall=36, gb_free=24, wall=3421
2022-09-29 18:52:13 | INFO | train_inner | epoch 035:    124 / 314 loss=3.987, nll_loss=2.17, ppl=4.5, wps=20943.3, ups=2.73, wpb=7667.7, bsz=325.5, num_updates=10800, lr=0.000608581, gnorm=1.061, train_wall=36, gb_free=23.5, wall=3458
2022-09-29 18:52:50 | INFO | train_inner | epoch 035:    224 / 314 loss=4.181, nll_loss=2.399, ppl=5.28, wps=22292.4, ups=2.74, wpb=8148.9, bsz=304.8, num_updates=10900, lr=0.000605783, gnorm=1.158, train_wall=36, gb_free=23.9, wall=3494
2022-09-29 18:53:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:53:22 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.214 | nll_loss 5.69 | ppl 51.62 | wps 48530 | wpb 4813.2 | bsz 188.9 | num_updates 10990 | best_loss 6.803
2022-09-29 18:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 10990 updates
2022-09-29 18:53:22 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint35.pt
2022-09-29 18:53:24 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint35.pt
2022-09-29 18:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint35.pt (epoch 35 @ 10990 updates, score 7.214) (writing took 4.465524648083374 seconds)
2022-09-29 18:53:27 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-09-29 18:53:27 | INFO | train | epoch 035 | loss 4.105 | nll_loss 2.309 | ppl 4.96 | wps 20313.1 | ups 2.63 | wpb 7710.3 | bsz 302.2 | num_updates 10990 | lr 0.000603297 | gnorm 1.107 | train_wall 113 | gb_free 23.8 | wall 3532
2022-09-29 18:53:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:53:27 | INFO | fairseq.trainer | begin training epoch 36
2022-09-29 18:53:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:53:31 | INFO | train_inner | epoch 036:     10 / 314 loss=4.177, nll_loss=2.395, ppl=5.26, wps=18138.8, ups=2.43, wpb=7478.3, bsz=272.5, num_updates=11000, lr=0.000603023, gnorm=1.106, train_wall=35, gb_free=23.3, wall=3536
2022-09-29 18:54:07 | INFO | train_inner | epoch 036:    110 / 314 loss=3.965, nll_loss=2.145, ppl=4.42, wps=20576.8, ups=2.78, wpb=7391.1, bsz=293.1, num_updates=11100, lr=0.0006003, gnorm=1.15, train_wall=36, gb_free=23.6, wall=3572
2022-09-29 18:54:44 | INFO | train_inner | epoch 036:    210 / 314 loss=4.075, nll_loss=2.276, ppl=4.84, wps=21067.4, ups=2.71, wpb=7783.5, bsz=297, num_updates=11200, lr=0.000597614, gnorm=1.06, train_wall=37, gb_free=23.4, wall=3609
2022-09-29 18:55:21 | INFO | train_inner | epoch 036:    310 / 314 loss=4.146, nll_loss=2.36, ppl=5.13, wps=20928.7, ups=2.69, wpb=7768.6, bsz=303.8, num_updates=11300, lr=0.000594964, gnorm=1.088, train_wall=37, gb_free=24.1, wall=3646
2022-09-29 18:55:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:55:24 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.193 | nll_loss 5.666 | ppl 50.79 | wps 48103.3 | wpb 4813.2 | bsz 188.9 | num_updates 11304 | best_loss 6.803
2022-09-29 18:55:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 11304 updates
2022-09-29 18:55:24 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint36.pt
2022-09-29 18:55:26 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint36.pt
2022-09-29 18:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint36.pt (epoch 36 @ 11304 updates, score 7.193) (writing took 4.464665069943294 seconds)
2022-09-29 18:55:28 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-09-29 18:55:28 | INFO | train | epoch 036 | loss 4.064 | nll_loss 2.262 | ppl 4.8 | wps 19923 | ups 2.58 | wpb 7710.3 | bsz 302.2 | num_updates 11304 | lr 0.000594859 | gnorm 1.093 | train_wall 115 | gb_free 24 | wall 3653
2022-09-29 18:55:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:55:28 | INFO | fairseq.trainer | begin training epoch 37
2022-09-29 18:55:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:56:05 | INFO | train_inner | epoch 037:     96 / 314 loss=3.915, nll_loss=2.088, ppl=4.25, wps=17607.5, ups=2.29, wpb=7689.9, bsz=284.8, num_updates=11400, lr=0.000592349, gnorm=1.033, train_wall=37, gb_free=23.9, wall=3689
2022-09-29 18:56:41 | INFO | train_inner | epoch 037:    196 / 314 loss=4.038, nll_loss=2.233, ppl=4.7, wps=21223.1, ups=2.72, wpb=7805.5, bsz=311.2, num_updates=11500, lr=0.000589768, gnorm=1.119, train_wall=37, gb_free=23.8, wall=3726
2022-09-29 18:57:17 | INFO | train_inner | epoch 037:    296 / 314 loss=4.111, nll_loss=2.318, ppl=4.99, wps=21780.6, ups=2.77, wpb=7855.2, bsz=319.9, num_updates=11600, lr=0.00058722, gnorm=1.088, train_wall=36, gb_free=24.3, wall=3762
2022-09-29 18:57:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:57:25 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.22 | nll_loss 5.702 | ppl 52.06 | wps 48075 | wpb 4813.2 | bsz 188.9 | num_updates 11618 | best_loss 6.803
2022-09-29 18:57:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 11618 updates
2022-09-29 18:57:25 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint37.pt
2022-09-29 18:57:27 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint37.pt
2022-09-29 18:57:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint37.pt (epoch 37 @ 11618 updates, score 7.22) (writing took 4.205081256106496 seconds)
2022-09-29 18:57:29 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-09-29 18:57:29 | INFO | train | epoch 037 | loss 4.018 | nll_loss 2.21 | ppl 4.63 | wps 19999.8 | ups 2.59 | wpb 7710.3 | bsz 302.2 | num_updates 11618 | lr 0.000586765 | gnorm 1.081 | train_wall 115 | gb_free 25 | wall 3774
2022-09-29 18:57:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:57:29 | INFO | fairseq.trainer | begin training epoch 38
2022-09-29 18:57:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:58:00 | INFO | train_inner | epoch 038:     82 / 314 loss=3.871, nll_loss=2.035, ppl=4.1, wps=17815.9, ups=2.35, wpb=7577.6, bsz=299.4, num_updates=11700, lr=0.000584705, gnorm=1.049, train_wall=37, gb_free=23.9, wall=3805
2022-09-29 18:58:37 | INFO | train_inner | epoch 038:    182 / 314 loss=3.976, nll_loss=2.161, ppl=4.47, wps=21327.5, ups=2.71, wpb=7868.1, bsz=320.2, num_updates=11800, lr=0.000582223, gnorm=1.076, train_wall=37, gb_free=23.7, wall=3842
2022-09-29 18:59:13 | INFO | train_inner | epoch 038:    282 / 314 loss=4.064, nll_loss=2.265, ppl=4.81, wps=20610.5, ups=2.75, wpb=7487.7, bsz=269.7, num_updates=11900, lr=0.000579771, gnorm=1.153, train_wall=36, gb_free=23.9, wall=3878
2022-09-29 18:59:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 18:59:26 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.223 | nll_loss 5.708 | ppl 52.28 | wps 48392 | wpb 4813.2 | bsz 188.9 | num_updates 11932 | best_loss 6.803
2022-09-29 18:59:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 11932 updates
2022-09-29 18:59:26 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint38.pt
2022-09-29 18:59:28 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint38.pt
2022-09-29 18:59:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint38.pt (epoch 38 @ 11932 updates, score 7.223) (writing took 3.9768875557929277 seconds)
2022-09-29 18:59:30 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-09-29 18:59:30 | INFO | train | epoch 038 | loss 3.979 | nll_loss 2.163 | ppl 4.48 | wps 20017.8 | ups 2.6 | wpb 7710.3 | bsz 302.2 | num_updates 11932 | lr 0.000578993 | gnorm 1.085 | train_wall 115 | gb_free 24.4 | wall 3895
2022-09-29 18:59:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 18:59:30 | INFO | fairseq.trainer | begin training epoch 39
2022-09-29 18:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 18:59:56 | INFO | train_inner | epoch 039:     68 / 314 loss=3.909, nll_loss=2.082, ppl=4.23, wps=18243.6, ups=2.34, wpb=7800.4, bsz=305.4, num_updates=12000, lr=0.00057735, gnorm=1, train_wall=37, gb_free=23.6, wall=3921
2022-09-29 19:00:31 | INFO | train_inner | epoch 039:    168 / 314 loss=3.893, nll_loss=2.065, ppl=4.18, wps=20782.4, ups=2.81, wpb=7406.1, bsz=283.1, num_updates=12100, lr=0.00057496, gnorm=1.136, train_wall=35, gb_free=24, wall=3956
2022-09-29 19:01:09 | INFO | train_inner | epoch 039:    268 / 314 loss=4.002, nll_loss=2.193, ppl=4.57, wps=21467, ups=2.7, wpb=7944.3, bsz=331.4, num_updates=12200, lr=0.000572598, gnorm=1.085, train_wall=37, gb_free=23.5, wall=3993
2022-09-29 19:01:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:01:26 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.256 | nll_loss 5.738 | ppl 53.37 | wps 48449.4 | wpb 4813.2 | bsz 188.9 | num_updates 12246 | best_loss 6.803
2022-09-29 19:01:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 12246 updates
2022-09-29 19:01:26 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint39.pt
2022-09-29 19:01:28 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint39.pt
2022-09-29 19:01:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint39.pt (epoch 39 @ 12246 updates, score 7.256) (writing took 3.81949422811158 seconds)
2022-09-29 19:01:30 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-09-29 19:01:30 | INFO | train | epoch 039 | loss 3.94 | nll_loss 2.119 | ppl 4.34 | wps 20224.7 | ups 2.62 | wpb 7710.3 | bsz 302.2 | num_updates 12246 | lr 0.000571522 | gnorm 1.082 | train_wall 114 | gb_free 24.6 | wall 4015
2022-09-29 19:01:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:01:30 | INFO | fairseq.trainer | begin training epoch 40
2022-09-29 19:01:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:01:50 | INFO | train_inner | epoch 040:     54 / 314 loss=3.911, nll_loss=2.085, ppl=4.24, wps=19005.5, ups=2.43, wpb=7830.6, bsz=297, num_updates=12300, lr=0.000570266, gnorm=1.047, train_wall=36, gb_free=24.1, wall=4035
2022-09-29 19:02:26 | INFO | train_inner | epoch 040:    154 / 314 loss=3.846, nll_loss=2.01, ppl=4.03, wps=20639.2, ups=2.74, wpb=7544, bsz=291, num_updates=12400, lr=0.000567962, gnorm=1.091, train_wall=36, gb_free=24.2, wall=4071
2022-09-29 19:03:03 | INFO | train_inner | epoch 040:    254 / 314 loss=3.933, nll_loss=2.112, ppl=4.32, wps=20550.1, ups=2.72, wpb=7541.9, bsz=308, num_updates=12500, lr=0.000565685, gnorm=1.119, train_wall=36, gb_free=23.7, wall=4108
2022-09-29 19:03:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:03:27 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.262 | nll_loss 5.75 | ppl 53.8 | wps 48288.7 | wpb 4813.2 | bsz 188.9 | num_updates 12560 | best_loss 6.803
2022-09-29 19:03:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 12560 updates
2022-09-29 19:03:27 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint40.pt
2022-09-29 19:03:29 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint40.pt
2022-09-29 19:03:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint40.pt (epoch 40 @ 12560 updates, score 7.262) (writing took 3.9772943400312215 seconds)
2022-09-29 19:03:31 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-09-29 19:03:31 | INFO | train | epoch 040 | loss 3.901 | nll_loss 2.074 | ppl 4.21 | wps 20053.7 | ups 2.6 | wpb 7710.3 | bsz 302.2 | num_updates 12560 | lr 0.000564333 | gnorm 1.083 | train_wall 115 | gb_free 24.7 | wall 4136
2022-09-29 19:03:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:03:31 | INFO | fairseq.trainer | begin training epoch 41
2022-09-29 19:03:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:03:46 | INFO | train_inner | epoch 041:     40 / 314 loss=3.922, nll_loss=2.098, ppl=4.28, wps=18881.6, ups=2.34, wpb=8065.9, bsz=312.2, num_updates=12600, lr=0.000563436, gnorm=1.038, train_wall=37, gb_free=23.6, wall=4151
2022-09-29 19:04:23 | INFO | train_inner | epoch 041:    140 / 314 loss=3.779, nll_loss=1.931, ppl=3.81, wps=20952.3, ups=2.68, wpb=7813.1, bsz=318.6, num_updates=12700, lr=0.000561214, gnorm=1.072, train_wall=37, gb_free=24.7, wall=4188
2022-09-29 19:05:00 | INFO | train_inner | epoch 041:    240 / 314 loss=3.911, nll_loss=2.087, ppl=4.25, wps=21157.8, ups=2.72, wpb=7777.1, bsz=314.8, num_updates=12800, lr=0.000559017, gnorm=1.063, train_wall=37, gb_free=23.8, wall=4225
2022-09-29 19:05:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:05:28 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.305 | nll_loss 5.808 | ppl 56.01 | wps 48381.7 | wpb 4813.2 | bsz 188.9 | num_updates 12874 | best_loss 6.803
2022-09-29 19:05:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 12874 updates
2022-09-29 19:05:28 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint41.pt
2022-09-29 19:05:30 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint41.pt
2022-09-29 19:05:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint41.pt (epoch 41 @ 12874 updates, score 7.305) (writing took 3.8965984750539064 seconds)
2022-09-29 19:05:32 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-09-29 19:05:32 | INFO | train | epoch 041 | loss 3.86 | nll_loss 2.026 | ppl 4.07 | wps 20022.1 | ups 2.6 | wpb 7710.3 | bsz 302.2 | num_updates 12874 | lr 0.000557408 | gnorm 1.072 | train_wall 115 | gb_free 23.8 | wall 4257
2022-09-29 19:05:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:05:32 | INFO | fairseq.trainer | begin training epoch 42
2022-09-29 19:05:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:05:42 | INFO | train_inner | epoch 042:     26 / 314 loss=3.898, nll_loss=2.072, ppl=4.2, wps=18003.2, ups=2.38, wpb=7560.9, bsz=289.5, num_updates=12900, lr=0.000556846, gnorm=1.096, train_wall=36, gb_free=24, wall=4267
2022-09-29 19:06:19 | INFO | train_inner | epoch 042:    126 / 314 loss=3.771, nll_loss=1.922, ppl=3.79, wps=20763.4, ups=2.65, wpb=7828, bsz=307.1, num_updates=13000, lr=0.0005547, gnorm=1.063, train_wall=37, gb_free=23.8, wall=4304
2022-09-29 19:06:56 | INFO | train_inner | epoch 042:    226 / 314 loss=3.853, nll_loss=2.019, ppl=4.05, wps=20121.2, ups=2.73, wpb=7369.9, bsz=284.1, num_updates=13100, lr=0.000552579, gnorm=1.155, train_wall=36, gb_free=23.7, wall=4341
2022-09-29 19:07:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:07:30 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.33 | nll_loss 5.828 | ppl 56.82 | wps 48169.2 | wpb 4813.2 | bsz 188.9 | num_updates 13188 | best_loss 6.803
2022-09-29 19:07:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 13188 updates
2022-09-29 19:07:30 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint42.pt
2022-09-29 19:07:31 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint42.pt
2022-09-29 19:07:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint42.pt (epoch 42 @ 13188 updates, score 7.33) (writing took 3.9237326309084892 seconds)
2022-09-29 19:07:33 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-09-29 19:07:33 | INFO | train | epoch 042 | loss 3.838 | nll_loss 2.002 | ppl 4 | wps 19889.9 | ups 2.58 | wpb 7710.3 | bsz 302.2 | num_updates 13188 | lr 0.000550732 | gnorm 1.1 | train_wall 115 | gb_free 24.1 | wall 4378
2022-09-29 19:07:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:07:33 | INFO | fairseq.trainer | begin training epoch 43
2022-09-29 19:07:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:07:38 | INFO | train_inner | epoch 043:     12 / 314 loss=3.898, nll_loss=2.073, ppl=4.21, wps=18227.8, ups=2.37, wpb=7678.3, bsz=299, num_updates=13200, lr=0.000550482, gnorm=1.099, train_wall=36, gb_free=23.8, wall=4383
2022-09-29 19:08:15 | INFO | train_inner | epoch 043:    112 / 314 loss=3.697, nll_loss=1.836, ppl=3.57, wps=21240.6, ups=2.7, wpb=7867.8, bsz=314.6, num_updates=13300, lr=0.000548408, gnorm=1.058, train_wall=37, gb_free=24, wall=4420
2022-09-29 19:08:52 | INFO | train_inner | epoch 043:    212 / 314 loss=3.828, nll_loss=1.992, ppl=3.98, wps=20462.7, ups=2.69, wpb=7619.2, bsz=284.3, num_updates=13400, lr=0.000546358, gnorm=1.092, train_wall=37, gb_free=23.8, wall=4457
2022-09-29 19:09:29 | INFO | train_inner | epoch 043:    312 / 314 loss=3.902, nll_loss=2.08, ppl=4.23, wps=21096.5, ups=2.72, wpb=7764.8, bsz=310.2, num_updates=13500, lr=0.000544331, gnorm=1.146, train_wall=37, gb_free=23.9, wall=4494
2022-09-29 19:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:09:31 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.331 | nll_loss 5.824 | ppl 56.64 | wps 48463.3 | wpb 4813.2 | bsz 188.9 | num_updates 13502 | best_loss 6.803
2022-09-29 19:09:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 13502 updates
2022-09-29 19:09:31 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint43.pt
2022-09-29 19:09:33 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint43.pt
2022-09-29 19:09:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint43.pt (epoch 43 @ 13502 updates, score 7.331) (writing took 3.8412661738693714 seconds)
2022-09-29 19:09:35 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-09-29 19:09:35 | INFO | train | epoch 043 | loss 3.801 | nll_loss 1.96 | ppl 3.89 | wps 19885 | ups 2.58 | wpb 7710.3 | bsz 302.2 | num_updates 13502 | lr 0.000544291 | gnorm 1.097 | train_wall 116 | gb_free 24.3 | wall 4500
2022-09-29 19:09:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:09:35 | INFO | fairseq.trainer | begin training epoch 44
2022-09-29 19:09:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:10:12 | INFO | train_inner | epoch 044:     98 / 314 loss=3.681, nll_loss=1.818, ppl=3.53, wps=17758.3, ups=2.35, wpb=7543.1, bsz=286.2, num_updates=13600, lr=0.000542326, gnorm=1.304, train_wall=37, gb_free=23.6, wall=4537
2022-09-29 19:10:49 | INFO | train_inner | epoch 044:    198 / 314 loss=3.777, nll_loss=1.934, ppl=3.82, wps=20796, ups=2.69, wpb=7719.2, bsz=287.8, num_updates=13700, lr=0.000540343, gnorm=1.106, train_wall=37, gb_free=23.7, wall=4574
2022-09-29 19:11:25 | INFO | train_inner | epoch 044:    298 / 314 loss=3.841, nll_loss=2.007, ppl=4.02, wps=21484.4, ups=2.75, wpb=7801.9, bsz=324.5, num_updates=13800, lr=0.000538382, gnorm=1.09, train_wall=36, gb_free=24.9, wall=4610
2022-09-29 19:11:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:11:32 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.325 | nll_loss 5.832 | ppl 56.96 | wps 48402.2 | wpb 4813.2 | bsz 188.9 | num_updates 13816 | best_loss 6.803
2022-09-29 19:11:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 13816 updates
2022-09-29 19:11:32 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint44.pt
2022-09-29 19:11:34 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint44.pt
2022-09-29 19:11:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint44.pt (epoch 44 @ 13816 updates, score 7.325) (writing took 4.024307247949764 seconds)
2022-09-29 19:11:36 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-09-29 19:11:36 | INFO | train | epoch 044 | loss 3.772 | nll_loss 1.927 | ppl 3.8 | wps 20006.3 | ups 2.59 | wpb 7710.3 | bsz 302.2 | num_updates 13816 | lr 0.00053807 | gnorm 1.165 | train_wall 115 | gb_free 23.6 | wall 4621
2022-09-29 19:11:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:11:36 | INFO | fairseq.trainer | begin training epoch 45
2022-09-29 19:11:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:12:07 | INFO | train_inner | epoch 045:     84 / 314 loss=3.664, nll_loss=1.8, ppl=3.48, wps=18255.9, ups=2.4, wpb=7603.7, bsz=330.2, num_updates=13900, lr=0.000536442, gnorm=1.08, train_wall=36, gb_free=24.2, wall=4652
2022-09-29 19:12:42 | INFO | train_inner | epoch 045:    184 / 314 loss=3.727, nll_loss=1.875, ppl=3.67, wps=21516.9, ups=2.8, wpb=7673.7, bsz=294.7, num_updates=14000, lr=0.000534522, gnorm=1.112, train_wall=35, gb_free=23.6, wall=4687
2022-09-29 19:13:19 | INFO | train_inner | epoch 045:    284 / 314 loss=3.824, nll_loss=1.99, ppl=3.97, wps=21407.9, ups=2.72, wpb=7881.4, bsz=289, num_updates=14100, lr=0.000532624, gnorm=1.094, train_wall=37, gb_free=23.8, wall=4724
2022-09-29 19:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:13:32 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.351 | nll_loss 5.853 | ppl 57.78 | wps 48383.4 | wpb 4813.2 | bsz 188.9 | num_updates 14130 | best_loss 6.803
2022-09-29 19:13:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 14130 updates
2022-09-29 19:13:32 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint45.pt
2022-09-29 19:13:34 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint45.pt
2022-09-29 19:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint45.pt (epoch 45 @ 14130 updates, score 7.351) (writing took 4.48346525686793 seconds)
2022-09-29 19:13:36 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-09-29 19:13:36 | INFO | train | epoch 045 | loss 3.741 | nll_loss 1.891 | ppl 3.71 | wps 20162.3 | ups 2.61 | wpb 7710.3 | bsz 302.2 | num_updates 14130 | lr 0.000532058 | gnorm 1.092 | train_wall 113 | gb_free 23.6 | wall 4741
2022-09-29 19:13:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:13:36 | INFO | fairseq.trainer | begin training epoch 46
2022-09-29 19:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:14:02 | INFO | train_inner | epoch 046:     70 / 314 loss=3.652, nll_loss=1.784, ppl=3.44, wps=18308.5, ups=2.33, wpb=7843.2, bsz=323.9, num_updates=14200, lr=0.000530745, gnorm=1.035, train_wall=37, gb_free=24.4, wall=4767
2022-09-29 19:14:39 | INFO | train_inner | epoch 046:    170 / 314 loss=3.672, nll_loss=1.811, ppl=3.51, wps=20463.2, ups=2.7, wpb=7590.2, bsz=294.9, num_updates=14300, lr=0.000528886, gnorm=1.095, train_wall=37, gb_free=23.8, wall=4804
2022-09-29 19:15:16 | INFO | train_inner | epoch 046:    270 / 314 loss=3.779, nll_loss=1.937, ppl=3.83, wps=21049.6, ups=2.7, wpb=7793.1, bsz=296.6, num_updates=14400, lr=0.000527046, gnorm=1.089, train_wall=37, gb_free=23.6, wall=4841
2022-09-29 19:15:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:15:34 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 7.414 | nll_loss 5.93 | ppl 60.99 | wps 48416.9 | wpb 4813.2 | bsz 188.9 | num_updates 14444 | best_loss 6.803
2022-09-29 19:15:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 14444 updates
2022-09-29 19:15:34 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint46.pt
2022-09-29 19:15:35 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint46.pt
2022-09-29 19:15:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint46.pt (epoch 46 @ 14444 updates, score 7.414) (writing took 4.21529466798529 seconds)
2022-09-29 19:15:38 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-09-29 19:15:38 | INFO | train | epoch 046 | loss 3.709 | nll_loss 1.854 | ppl 3.62 | wps 19910.6 | ups 2.58 | wpb 7710.3 | bsz 302.2 | num_updates 14444 | lr 0.000526243 | gnorm 1.081 | train_wall 115 | gb_free 24 | wall 4863
2022-09-29 19:15:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:15:38 | INFO | fairseq.trainer | begin training epoch 47
2022-09-29 19:15:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:15:58 | INFO | train_inner | epoch 047:     56 / 314 loss=3.701, nll_loss=1.846, ppl=3.59, wps=17892.8, ups=2.39, wpb=7497, bsz=255.2, num_updates=14500, lr=0.000525226, gnorm=1.088, train_wall=36, gb_free=23.7, wall=4883
2022-09-29 19:16:36 | INFO | train_inner | epoch 047:    156 / 314 loss=3.676, nll_loss=1.817, ppl=3.52, wps=21580.4, ups=2.68, wpb=8057.8, bsz=304, num_updates=14600, lr=0.000523424, gnorm=1.064, train_wall=37, gb_free=24.4, wall=4920
2022-09-29 19:17:12 | INFO | train_inner | epoch 047:    256 / 314 loss=3.718, nll_loss=1.865, ppl=3.64, wps=19877.7, ups=2.73, wpb=7277, bsz=297.3, num_updates=14700, lr=0.000521641, gnorm=1.16, train_wall=36, gb_free=24.7, wall=4957
2022-09-29 19:17:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:17:35 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 7.39 | nll_loss 5.897 | ppl 59.61 | wps 48480.3 | wpb 4813.2 | bsz 188.9 | num_updates 14758 | best_loss 6.803
2022-09-29 19:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 14758 updates
2022-09-29 19:17:35 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint47.pt
2022-09-29 19:17:36 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint47.pt
2022-09-29 19:17:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint47.pt (epoch 47 @ 14758 updates, score 7.39) (writing took 3.882039966993034 seconds)
2022-09-29 19:17:39 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-09-29 19:17:39 | INFO | train | epoch 047 | loss 3.688 | nll_loss 1.831 | ppl 3.56 | wps 20063.2 | ups 2.6 | wpb 7710.3 | bsz 302.2 | num_updates 14758 | lr 0.000520614 | gnorm 1.102 | train_wall 115 | gb_free 25.7 | wall 4983
2022-09-29 19:17:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:17:39 | INFO | fairseq.trainer | begin training epoch 48
2022-09-29 19:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:17:54 | INFO | train_inner | epoch 048:     42 / 314 loss=3.668, nll_loss=1.807, ppl=3.5, wps=18642.3, ups=2.38, wpb=7820.2, bsz=336.2, num_updates=14800, lr=0.000519875, gnorm=1.102, train_wall=36, gb_free=24, wall=4999
2022-09-29 19:18:31 | INFO | train_inner | epoch 048:    142 / 314 loss=3.586, nll_loss=1.711, ppl=3.27, wps=20718.9, ups=2.72, wpb=7621.7, bsz=300.9, num_updates=14900, lr=0.000518128, gnorm=1.074, train_wall=37, gb_free=24, wall=5036
2022-09-29 19:19:07 | INFO | train_inner | epoch 048:    242 / 314 loss=3.684, nll_loss=1.827, ppl=3.55, wps=21413.5, ups=2.75, wpb=7800.3, bsz=327.9, num_updates=15000, lr=0.000516398, gnorm=1.11, train_wall=36, gb_free=23.8, wall=5072
2022-09-29 19:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:19:36 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.396 | nll_loss 5.908 | ppl 60.04 | wps 48799.8 | wpb 4813.2 | bsz 188.9 | num_updates 15072 | best_loss 6.803
2022-09-29 19:19:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 15072 updates
2022-09-29 19:19:36 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint48.pt
2022-09-29 19:19:38 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint48.pt
2022-09-29 19:19:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint48.pt (epoch 48 @ 15072 updates, score 7.396) (writing took 3.786354178097099 seconds)
2022-09-29 19:19:40 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-09-29 19:19:40 | INFO | train | epoch 048 | loss 3.654 | nll_loss 1.791 | ppl 3.46 | wps 20003 | ups 2.59 | wpb 7710.3 | bsz 302.2 | num_updates 15072 | lr 0.000515163 | gnorm 1.085 | train_wall 115 | gb_free 23.9 | wall 5104
2022-09-29 19:19:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:19:40 | INFO | fairseq.trainer | begin training epoch 49
2022-09-29 19:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:19:50 | INFO | train_inner | epoch 049:     28 / 314 loss=3.69, nll_loss=1.833, ppl=3.56, wps=18193.4, ups=2.33, wpb=7813.4, bsz=281.4, num_updates=15100, lr=0.000514685, gnorm=1.051, train_wall=37, gb_free=24.4, wall=5115
2022-09-29 19:20:26 | INFO | train_inner | epoch 049:    128 / 314 loss=3.562, nll_loss=1.685, ppl=3.22, wps=21610.7, ups=2.76, wpb=7828.5, bsz=326.5, num_updates=15200, lr=0.000512989, gnorm=1.086, train_wall=36, gb_free=23.8, wall=5151
2022-09-29 19:21:03 | INFO | train_inner | epoch 049:    228 / 314 loss=3.659, nll_loss=1.797, ppl=3.47, wps=21198.5, ups=2.77, wpb=7643.8, bsz=279.7, num_updates=15300, lr=0.00051131, gnorm=1.097, train_wall=36, gb_free=23.6, wall=5187
2022-09-29 19:21:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:21:35 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.458 | nll_loss 5.968 | ppl 62.6 | wps 48247.9 | wpb 4813.2 | bsz 188.9 | num_updates 15386 | best_loss 6.803
2022-09-29 19:21:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 15386 updates
2022-09-29 19:21:35 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint49.pt
2022-09-29 19:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint49.pt
2022-09-29 19:21:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint49.pt (epoch 49 @ 15386 updates, score 7.458) (writing took 3.8446518189739436 seconds)
2022-09-29 19:21:39 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-09-29 19:21:39 | INFO | train | epoch 049 | loss 3.633 | nll_loss 1.767 | ppl 3.4 | wps 20288.5 | ups 2.63 | wpb 7710.3 | bsz 302.2 | num_updates 15386 | lr 0.000509879 | gnorm 1.108 | train_wall 113 | gb_free 23.5 | wall 5224
2022-09-29 19:21:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:21:39 | INFO | fairseq.trainer | begin training epoch 50
2022-09-29 19:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:21:45 | INFO | train_inner | epoch 050:     14 / 314 loss=3.706, nll_loss=1.855, ppl=3.62, wps=18617.4, ups=2.38, wpb=7834.1, bsz=307.4, num_updates=15400, lr=0.000509647, gnorm=1.149, train_wall=36, gb_free=23.6, wall=5229
2022-09-29 19:22:21 | INFO | train_inner | epoch 050:    114 / 314 loss=3.5, nll_loss=1.612, ppl=3.06, wps=20377.1, ups=2.75, wpb=7397.8, bsz=312.4, num_updates=15500, lr=0.000508001, gnorm=1.058, train_wall=36, gb_free=23.4, wall=5266
2022-09-29 19:22:57 | INFO | train_inner | epoch 050:    214 / 314 loss=3.625, nll_loss=1.761, ppl=3.39, wps=21282.2, ups=2.77, wpb=7677.8, bsz=287.7, num_updates=15600, lr=0.00050637, gnorm=1.102, train_wall=36, gb_free=24, wall=5302
2022-09-29 19:23:33 | INFO | train_inner | epoch 050:    314 / 314 loss=3.696, nll_loss=1.843, ppl=3.59, wps=21971.7, ups=2.78, wpb=7891.7, bsz=300.5, num_updates=15700, lr=0.000504754, gnorm=1.095, train_wall=36, gb_free=23.8, wall=5338
2022-09-29 19:23:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:23:34 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.446 | nll_loss 5.964 | ppl 62.43 | wps 48117.7 | wpb 4813.2 | bsz 188.9 | num_updates 15700 | best_loss 6.803
2022-09-29 19:23:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 15700 updates
2022-09-29 19:23:34 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint50.pt
2022-09-29 19:23:36 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint50.pt
2022-09-29 19:23:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint50.pt (epoch 50 @ 15700 updates, score 7.446) (writing took 4.170674928929657 seconds)
2022-09-29 19:23:38 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-09-29 19:23:38 | INFO | train | epoch 050 | loss 3.605 | nll_loss 1.736 | ppl 3.33 | wps 20259.5 | ups 2.63 | wpb 7710.3 | bsz 302.2 | num_updates 15700 | lr 0.000504754 | gnorm 1.079 | train_wall 113 | gb_free 23.8 | wall 5343
2022-09-29 19:23:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:23:38 | INFO | fairseq.trainer | begin training epoch 51
2022-09-29 19:23:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:24:14 | INFO | train_inner | epoch 051:    100 / 314 loss=3.47, nll_loss=1.577, ppl=2.98, wps=17647.1, ups=2.46, wpb=7184.5, bsz=277.9, num_updates=15800, lr=0.000503155, gnorm=1.1, train_wall=35, gb_free=24, wall=5378
2022-09-29 19:24:51 | INFO | train_inner | epoch 051:    200 / 314 loss=3.579, nll_loss=1.707, ppl=3.26, wps=21186, ups=2.7, wpb=7835.5, bsz=329.3, num_updates=15900, lr=0.00050157, gnorm=1.105, train_wall=37, gb_free=24.2, wall=5415
2022-09-29 19:25:27 | INFO | train_inner | epoch 051:    300 / 314 loss=3.671, nll_loss=1.815, ppl=3.52, wps=21854.3, ups=2.73, wpb=8011.3, bsz=303.4, num_updates=16000, lr=0.0005, gnorm=1.085, train_wall=36, gb_free=23.4, wall=5452
2022-09-29 19:25:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:25:34 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.433 | nll_loss 5.948 | ppl 61.73 | wps 48419.3 | wpb 4813.2 | bsz 188.9 | num_updates 16014 | best_loss 6.803
2022-09-29 19:25:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 16014 updates
2022-09-29 19:25:34 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint51.pt
2022-09-29 19:25:36 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint51.pt
2022-09-29 19:25:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint51.pt (epoch 51 @ 16014 updates, score 7.433) (writing took 4.059148976113647 seconds)
2022-09-29 19:25:38 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-09-29 19:25:38 | INFO | train | epoch 051 | loss 3.583 | nll_loss 1.712 | ppl 3.28 | wps 20246.1 | ups 2.63 | wpb 7710.3 | bsz 302.2 | num_updates 16014 | lr 0.000499781 | gnorm 1.095 | train_wall 113 | gb_free 23.8 | wall 5463
2022-09-29 19:25:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:25:38 | INFO | fairseq.trainer | begin training epoch 52
2022-09-29 19:25:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:26:09 | INFO | train_inner | epoch 052:     86 / 314 loss=3.484, nll_loss=1.594, ppl=3.02, wps=18213.1, ups=2.37, wpb=7672.3, bsz=266.6, num_updates=16100, lr=0.000498445, gnorm=1.051, train_wall=36, gb_free=23.7, wall=5494
2022-09-29 19:26:46 | INFO | train_inner | epoch 052:    186 / 314 loss=3.546, nll_loss=1.669, ppl=3.18, wps=20966, ups=2.75, wpb=7635.2, bsz=299.3, num_updates=16200, lr=0.000496904, gnorm=1.074, train_wall=36, gb_free=23.8, wall=5531
2022-09-29 19:27:23 | INFO | train_inner | epoch 052:    286 / 314 loss=3.635, nll_loss=1.775, ppl=3.42, wps=21355.8, ups=2.71, wpb=7885.4, bsz=316, num_updates=16300, lr=0.000495377, gnorm=1.105, train_wall=37, gb_free=23.7, wall=5568
2022-09-29 19:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:27:34 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 7.468 | nll_loss 5.997 | ppl 63.87 | wps 48412.6 | wpb 4813.2 | bsz 188.9 | num_updates 16328 | best_loss 6.803
2022-09-29 19:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 16328 updates
2022-09-29 19:27:34 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint52.pt
2022-09-29 19:27:36 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint52.pt
2022-09-29 19:27:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint52.pt (epoch 52 @ 16328 updates, score 7.468) (writing took 3.987493355991319 seconds)
2022-09-29 19:27:38 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-09-29 19:27:38 | INFO | train | epoch 052 | loss 3.556 | nll_loss 1.68 | ppl 3.21 | wps 20119.6 | ups 2.61 | wpb 7710.3 | bsz 302.2 | num_updates 16328 | lr 0.000494952 | gnorm 1.089 | train_wall 114 | gb_free 26.9 | wall 5583
2022-09-29 19:27:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:27:38 | INFO | fairseq.trainer | begin training epoch 53
2022-09-29 19:27:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:28:05 | INFO | train_inner | epoch 053:     72 / 314 loss=3.488, nll_loss=1.598, ppl=3.03, wps=18043, ups=2.39, wpb=7547, bsz=312.9, num_updates=16400, lr=0.000493865, gnorm=1.109, train_wall=36, gb_free=24.7, wall=5609
2022-09-29 19:28:41 | INFO | train_inner | epoch 053:    172 / 314 loss=3.513, nll_loss=1.631, ppl=3.1, wps=21595.4, ups=2.73, wpb=7912.5, bsz=306.5, num_updates=16500, lr=0.000492366, gnorm=1.093, train_wall=36, gb_free=23.3, wall=5646
2022-09-29 19:29:18 | INFO | train_inner | epoch 053:    272 / 314 loss=3.59, nll_loss=1.721, ppl=3.3, wps=20490, ups=2.69, wpb=7624.9, bsz=283.6, num_updates=16600, lr=0.000490881, gnorm=1.127, train_wall=37, gb_free=24.9, wall=5683
2022-09-29 19:29:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:29:35 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 7.481 | nll_loss 6.01 | ppl 64.43 | wps 48424.3 | wpb 4813.2 | bsz 188.9 | num_updates 16642 | best_loss 6.803
2022-09-29 19:29:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 16642 updates
2022-09-29 19:29:35 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint53.pt
2022-09-29 19:29:37 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint53.pt
2022-09-29 19:29:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint53.pt (epoch 53 @ 16642 updates, score 7.481) (writing took 4.012153605930507 seconds)
2022-09-29 19:29:39 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-09-29 19:29:39 | INFO | train | epoch 053 | loss 3.534 | nll_loss 1.655 | ppl 3.15 | wps 20005.1 | ups 2.59 | wpb 7710.3 | bsz 302.2 | num_updates 16642 | lr 0.000490261 | gnorm 1.101 | train_wall 115 | gb_free 24 | wall 5704
2022-09-29 19:29:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:29:39 | INFO | fairseq.trainer | begin training epoch 54
2022-09-29 19:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:30:01 | INFO | train_inner | epoch 054:     58 / 314 loss=3.5, nll_loss=1.615, ppl=3.06, wps=18322.8, ups=2.35, wpb=7786.6, bsz=332.5, num_updates=16700, lr=0.000489409, gnorm=1.058, train_wall=37, gb_free=24.5, wall=5726
2022-09-29 19:30:37 | INFO | train_inner | epoch 054:    158 / 314 loss=3.48, nll_loss=1.592, ppl=3.02, wps=20922.4, ups=2.74, wpb=7630, bsz=275, num_updates=16800, lr=0.00048795, gnorm=1.115, train_wall=36, gb_free=25.7, wall=5762
2022-09-29 19:31:15 | INFO | train_inner | epoch 054:    258 / 314 loss=3.579, nll_loss=1.71, ppl=3.27, wps=20985, ups=2.65, wpb=7932.4, bsz=342.6, num_updates=16900, lr=0.000486504, gnorm=1.109, train_wall=38, gb_free=24.6, wall=5800
2022-09-29 19:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:31:36 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 7.488 | nll_loss 6.026 | ppl 65.18 | wps 48186.9 | wpb 4813.2 | bsz 188.9 | num_updates 16956 | best_loss 6.803
2022-09-29 19:31:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 16956 updates
2022-09-29 19:31:36 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint54.pt
2022-09-29 19:31:38 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint54.pt
2022-09-29 19:31:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint54.pt (epoch 54 @ 16956 updates, score 7.488) (writing took 3.8690551549661905 seconds)
2022-09-29 19:31:40 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-09-29 19:31:40 | INFO | train | epoch 054 | loss 3.514 | nll_loss 1.632 | ppl 3.1 | wps 20013.2 | ups 2.6 | wpb 7710.3 | bsz 302.2 | num_updates 16956 | lr 0.0004857 | gnorm 1.097 | train_wall 115 | gb_free 23.5 | wall 5825
2022-09-29 19:31:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:31:40 | INFO | fairseq.trainer | begin training epoch 55
2022-09-29 19:31:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:31:56 | INFO | train_inner | epoch 055:     44 / 314 loss=3.504, nll_loss=1.621, ppl=3.08, wps=18635.8, ups=2.42, wpb=7693.9, bsz=279.7, num_updates=17000, lr=0.000485071, gnorm=1.106, train_wall=36, gb_free=23.8, wall=5841
2022-09-29 19:32:33 | INFO | train_inner | epoch 055:    144 / 314 loss=3.445, nll_loss=1.552, ppl=2.93, wps=20913.5, ups=2.74, wpb=7640.1, bsz=307.1, num_updates=17100, lr=0.000483651, gnorm=1.057, train_wall=36, gb_free=24.1, wall=5878
2022-09-29 19:33:09 | INFO | train_inner | epoch 055:    244 / 314 loss=3.52, nll_loss=1.641, ppl=3.12, wps=20930.4, ups=2.74, wpb=7628.2, bsz=311.7, num_updates=17200, lr=0.000482243, gnorm=1.143, train_wall=36, gb_free=24.1, wall=5914
2022-09-29 19:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:33:36 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 7.499 | nll_loss 6.033 | ppl 65.47 | wps 48457.1 | wpb 4813.2 | bsz 188.9 | num_updates 17270 | best_loss 6.803
2022-09-29 19:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 17270 updates
2022-09-29 19:33:36 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint55.pt
2022-09-29 19:33:38 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint55.pt
2022-09-29 19:33:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint55.pt (epoch 55 @ 17270 updates, score 7.499) (writing took 4.025764368008822 seconds)
2022-09-29 19:33:40 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-09-29 19:33:40 | INFO | train | epoch 055 | loss 3.493 | nll_loss 1.608 | ppl 3.05 | wps 20186.6 | ups 2.62 | wpb 7710.3 | bsz 302.2 | num_updates 17270 | lr 0.000481264 | gnorm 1.095 | train_wall 114 | gb_free 24.1 | wall 5945
2022-09-29 19:33:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:33:40 | INFO | fairseq.trainer | begin training epoch 56
2022-09-29 19:33:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:33:52 | INFO | train_inner | epoch 056:     30 / 314 loss=3.508, nll_loss=1.627, ppl=3.09, wps=18847.5, ups=2.37, wpb=7945.6, bsz=299.2, num_updates=17300, lr=0.000480847, gnorm=1.054, train_wall=36, gb_free=24.2, wall=5956
2022-09-29 19:34:28 | INFO | train_inner | epoch 056:    130 / 314 loss=3.41, nll_loss=1.514, ppl=2.86, wps=20436.9, ups=2.74, wpb=7455.6, bsz=267.5, num_updates=17400, lr=0.000479463, gnorm=1.052, train_wall=36, gb_free=24.3, wall=5993
2022-09-29 19:35:05 | INFO | train_inner | epoch 056:    230 / 314 loss=3.506, nll_loss=1.624, ppl=3.08, wps=21621.5, ups=2.69, wpb=8050.6, bsz=339.9, num_updates=17500, lr=0.000478091, gnorm=1.156, train_wall=37, gb_free=24, wall=6030
2022-09-29 19:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:35:37 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 7.544 | nll_loss 6.076 | ppl 67.47 | wps 48252 | wpb 4813.2 | bsz 188.9 | num_updates 17584 | best_loss 6.803
2022-09-29 19:35:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 17584 updates
2022-09-29 19:35:37 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint56.pt
2022-09-29 19:35:39 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint56.pt
2022-09-29 19:35:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint56.pt (epoch 56 @ 17584 updates, score 7.544) (writing took 3.8744497180450708 seconds)
2022-09-29 19:35:41 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-09-29 19:35:41 | INFO | train | epoch 056 | loss 3.473 | nll_loss 1.586 | ppl 3 | wps 20047 | ups 2.6 | wpb 7710.3 | bsz 302.2 | num_updates 17584 | lr 0.000476948 | gnorm 1.11 | train_wall 114 | gb_free 24 | wall 6066
2022-09-29 19:35:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:35:41 | INFO | fairseq.trainer | begin training epoch 57
2022-09-29 19:35:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:35:47 | INFO | train_inner | epoch 057:     16 / 314 loss=3.516, nll_loss=1.637, ppl=3.11, wps=17697.5, ups=2.4, wpb=7382.4, bsz=284.4, num_updates=17600, lr=0.000476731, gnorm=1.14, train_wall=36, gb_free=24, wall=6072
2022-09-29 19:36:24 | INFO | train_inner | epoch 057:    116 / 314 loss=3.386, nll_loss=1.484, ppl=2.8, wps=21202.3, ups=2.72, wpb=7784.7, bsz=287.9, num_updates=17700, lr=0.000475383, gnorm=1.053, train_wall=36, gb_free=24.1, wall=6109
2022-09-29 19:37:01 | INFO | train_inner | epoch 057:    216 / 314 loss=3.47, nll_loss=1.584, ppl=3, wps=21947.4, ups=2.72, wpb=8072.8, bsz=325, num_updates=17800, lr=0.000474045, gnorm=1.058, train_wall=36, gb_free=24.2, wall=6145
2022-09-29 19:37:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:37:37 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 7.553 | nll_loss 6.094 | ppl 68.31 | wps 47514.2 | wpb 4813.2 | bsz 188.9 | num_updates 17898 | best_loss 6.803
2022-09-29 19:37:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 17898 updates
2022-09-29 19:37:37 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint57.pt
2022-09-29 19:37:39 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint57.pt
2022-09-29 19:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint57.pt (epoch 57 @ 17898 updates, score 7.553) (writing took 3.961129850940779 seconds)
2022-09-29 19:37:41 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-09-29 19:37:41 | INFO | train | epoch 057 | loss 3.449 | nll_loss 1.559 | ppl 2.95 | wps 20142.1 | ups 2.61 | wpb 7710.3 | bsz 302.2 | num_updates 17898 | lr 0.000472746 | gnorm 1.081 | train_wall 114 | gb_free 23.8 | wall 6186
2022-09-29 19:37:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:37:41 | INFO | fairseq.trainer | begin training epoch 58
2022-09-29 19:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:37:42 | INFO | train_inner | epoch 058:      2 / 314 loss=3.502, nll_loss=1.621, ppl=3.08, wps=17521, ups=2.41, wpb=7282.9, bsz=296.3, num_updates=17900, lr=0.000472719, gnorm=1.148, train_wall=36, gb_free=23.5, wall=6187
2022-09-29 19:38:18 | INFO | train_inner | epoch 058:    102 / 314 loss=3.343, nll_loss=1.433, ppl=2.7, wps=21520.9, ups=2.78, wpb=7749.6, bsz=315.3, num_updates=18000, lr=0.000471405, gnorm=1.062, train_wall=36, gb_free=24.6, wall=6223
2022-09-29 19:38:54 | INFO | train_inner | epoch 058:    202 / 314 loss=3.422, nll_loss=1.529, ppl=2.89, wps=20955.4, ups=2.75, wpb=7612.8, bsz=299, num_updates=18100, lr=0.0004701, gnorm=1.061, train_wall=36, gb_free=24, wall=6259
2022-09-29 19:39:31 | INFO | train_inner | epoch 058:    302 / 314 loss=3.526, nll_loss=1.653, ppl=3.15, wps=21218.2, ups=2.73, wpb=7759.7, bsz=297.6, num_updates=18200, lr=0.000468807, gnorm=1.1, train_wall=36, gb_free=23.8, wall=6296
2022-09-29 19:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:39:37 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 7.581 | nll_loss 6.117 | ppl 69.4 | wps 47767.5 | wpb 4813.2 | bsz 188.9 | num_updates 18212 | best_loss 6.803
2022-09-29 19:39:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 18212 updates
2022-09-29 19:39:37 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint58.pt
2022-09-29 19:39:39 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint58.pt
2022-09-29 19:39:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint58.pt (epoch 58 @ 18212 updates, score 7.581) (writing took 3.942511119879782 seconds)
2022-09-29 19:39:41 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-09-29 19:39:41 | INFO | train | epoch 058 | loss 3.434 | nll_loss 1.543 | ppl 2.91 | wps 20255.6 | ups 2.63 | wpb 7710.3 | bsz 302.2 | num_updates 18212 | lr 0.000468653 | gnorm 1.074 | train_wall 113 | gb_free 23.7 | wall 6306
2022-09-29 19:39:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:39:41 | INFO | fairseq.trainer | begin training epoch 59
2022-09-29 19:39:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:40:13 | INFO | train_inner | epoch 059:     88 / 314 loss=3.363, nll_loss=1.461, ppl=2.75, wps=18640.4, ups=2.39, wpb=7797.4, bsz=294.9, num_updates=18300, lr=0.000467525, gnorm=1.022, train_wall=36, gb_free=23.8, wall=6338
2022-09-29 19:40:50 | INFO | train_inner | epoch 059:    188 / 314 loss=3.415, nll_loss=1.522, ppl=2.87, wps=21383.9, ups=2.72, wpb=7871.3, bsz=309.9, num_updates=18400, lr=0.000466252, gnorm=1.082, train_wall=37, gb_free=24.1, wall=6375
2022-09-29 19:41:25 | INFO | train_inner | epoch 059:    288 / 314 loss=3.48, nll_loss=1.598, ppl=3.03, wps=21675, ups=2.8, wpb=7734.4, bsz=313.7, num_updates=18500, lr=0.000464991, gnorm=1.133, train_wall=35, gb_free=24, wall=6410
2022-09-29 19:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:41:36 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 7.58 | nll_loss 6.122 | ppl 69.63 | wps 48441.8 | wpb 4813.2 | bsz 188.9 | num_updates 18526 | best_loss 6.803
2022-09-29 19:41:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 18526 updates
2022-09-29 19:41:36 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint59.pt
2022-09-29 19:41:38 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint59.pt
2022-09-29 19:41:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint59.pt (epoch 59 @ 18526 updates, score 7.58) (writing took 3.944873013999313 seconds)
2022-09-29 19:41:40 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-09-29 19:41:40 | INFO | train | epoch 059 | loss 3.414 | nll_loss 1.52 | ppl 2.87 | wps 20320.7 | ups 2.64 | wpb 7710.3 | bsz 302.2 | num_updates 18526 | lr 0.000464664 | gnorm 1.079 | train_wall 113 | gb_free 24.3 | wall 6425
2022-09-29 19:41:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:41:40 | INFO | fairseq.trainer | begin training epoch 60
2022-09-29 19:41:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-09-29 19:42:06 | INFO | train_inner | epoch 060:     74 / 314 loss=3.336, nll_loss=1.427, ppl=2.69, wps=17709.1, ups=2.43, wpb=7282.3, bsz=274, num_updates=18600, lr=0.000463739, gnorm=1.116, train_wall=35, gb_free=24.6, wall=6451
2022-09-29 19:42:43 | INFO | train_inner | epoch 060:    174 / 314 loss=3.376, nll_loss=1.478, ppl=2.79, wps=20948.4, ups=2.75, wpb=7616.5, bsz=304, num_updates=18700, lr=0.000462497, gnorm=1.055, train_wall=36, gb_free=23.6, wall=6488
2022-09-29 19:43:20 | INFO | train_inner | epoch 060:    274 / 314 loss=3.455, nll_loss=1.571, ppl=2.97, wps=21381.4, ups=2.68, wpb=7970.4, bsz=332, num_updates=18800, lr=0.000461266, gnorm=1.094, train_wall=37, gb_free=23.8, wall=6525
2022-09-29 19:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-09-29 19:43:36 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 7.613 | nll_loss 6.156 | ppl 71.31 | wps 48247.2 | wpb 4813.2 | bsz 188.9 | num_updates 18840 | best_loss 6.803
2022-09-29 19:43:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 18840 updates
2022-09-29 19:43:36 | INFO | fairseq.trainer | Saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint60.pt
2022-09-29 19:43:38 | INFO | fairseq.trainer | Finished saving checkpoint to /public/home/hang/桌面/test_train/test_train/nmt/models/zh_fr_train/checkpoints/checkpoint60.pt
2022-09-29 19:43:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./nmt/models/zh_fr_train/checkpoints/checkpoint60.pt (epoch 60 @ 18840 updates, score 7.613) (writing took 3.9882854979950935 seconds)
2022-09-29 19:43:40 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-09-29 19:43:40 | INFO | train | epoch 060 | loss 3.401 | nll_loss 1.506 | ppl 2.84 | wps 20190.4 | ups 2.62 | wpb 7710.3 | bsz 302.2 | num_updates 18840 | lr 0.000460776 | gnorm 1.087 | train_wall 114 | gb_free 23.6 | wall 6545
2022-09-29 19:43:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 314
2022-09-29 19:43:40 | INFO | fairseq.trainer | begin training epoch 61
2022-09-29 19:43:40 | INFO | fairseq_cli.train | Start iterating over samples
